{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tiktoken","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:55:58.250067Z","iopub.execute_input":"2024-09-10T07:55:58.250476Z","iopub.status.idle":"2024-09-10T07:56:16.140959Z","shell.execute_reply.started":"2024-09-10T07:55:58.250436Z","shell.execute_reply":"2024-09-10T07:56:16.139514Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting tiktoken\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\nDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tiktoken\nSuccessfully installed tiktoken-0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from importlib.metadata import version\n\nprint(\"torch version:\", version(\"torch\"))\nprint(\"tiktoken version:\", version(\"tiktoken\"))","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:16.143475Z","iopub.execute_input":"2024-09-10T07:56:16.143849Z","iopub.status.idle":"2024-09-10T07:56:16.180034Z","shell.execute_reply.started":"2024-09-10T07:56:16.143815Z","shell.execute_reply":"2024-09-10T07:56:16.178858Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"torch version: 2.1.2+cpu\ntiktoken version: 0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import urllib\n\n# URL of the PDF file\nurl = \"https://ag.gov.np/files/Constitution-of-Nepal_2072_Eng_www.moljpa.gov_.npDate-72_11_16.pdf\"\n\n# Open the URL and download the PDF\nresponse = urllib.request.urlopen(url)\npdf_data = response.read()\n\n# Save the PDF to a local file\nwith open(\"Constitution-of-Nepal_2072_Eng.pdf\", \"wb\") as f:\n    f.write(pdf_data)\n\nprint(\"PDF downloaded and saved as 'Constitution-of-Nepal_2072_Eng.pdf'\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:16.181545Z","iopub.execute_input":"2024-09-10T07:56:16.181931Z","iopub.status.idle":"2024-09-10T07:56:18.314519Z","shell.execute_reply.started":"2024-09-10T07:56:16.181889Z","shell.execute_reply":"2024-09-10T07:56:18.313150Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"PDF downloaded and saved as 'Constitution-of-Nepal_2072_Eng.pdf'\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install PyPDF2","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:18.318123Z","iopub.execute_input":"2024-09-10T07:56:18.318584Z","iopub.status.idle":"2024-09-10T07:56:34.140667Z","shell.execute_reply.started":"2024-09-10T07:56:18.318545Z","shell.execute_reply":"2024-09-10T07:56:34.139378Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import PyPDF2\n\n# Open the downloaded PDF file\nwith open(\"Constitution-of-Nepal_2072_Eng.pdf\", \"rb\") as file:\n    # Initialize a PDF reader object\n    pdf_reader = PyPDF2.PdfReader(file)\n    \n    # Extract text from each page of the PDF\n    raw_text = \"\"\n    for page_num in range(len(pdf_reader.pages)):\n        page = pdf_reader.pages[page_num]\n        raw_text += page.extract_text()\n\n# Print the first 500 characters to preview the content\nprint(raw_text[:50])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:34.142410Z","iopub.execute_input":"2024-09-10T07:56:34.142762Z","iopub.status.idle":"2024-09-10T07:56:43.732306Z","shell.execute_reply.started":"2024-09-10T07:56:34.142729Z","shell.execute_reply":"2024-09-10T07:56:43.730951Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":" \n1 \n  \n \n \n \nTHE CONSTITUTION OF NEPAL  \n   \n2 \n \n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(raw_text))","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:43.733678Z","iopub.execute_input":"2024-09-10T07:56:43.734058Z","iopub.status.idle":"2024-09-10T07:56:43.739788Z","shell.execute_reply.started":"2024-09-10T07:56:43.734029Z","shell.execute_reply":"2024-09-10T07:56:43.738639Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"344782\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Split text into tokens**","metadata":{}},{"cell_type":"code","source":"import re\npreprocessed = re.split(r'([,.:;?_!-\"()\\']|--|\\s|[@#%&])', raw_text)\n\npreprocessed = [item.strip() for item in preprocessed if item.strip()]\nprint(preprocessed[:30])","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:43.741635Z","iopub.execute_input":"2024-09-10T07:56:43.742022Z","iopub.status.idle":"2024-09-10T07:56:43.846401Z","shell.execute_reply.started":"2024-09-10T07:56:43.741992Z","shell.execute_reply":"2024-09-10T07:56:43.845064Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"['1', 'THE', 'CONSTITUTION', 'OF', 'NEPAL', '2', 'Table', 'of', 'Content', 's', 'Preamble', 'Part-1', 'Preliminary', 'Part-2', 'Citizenship', 'Part-3', 'Fundamental', 'Rights', 'and', 'Duties', 'Part-4', 'Directive', 'Principles', ',', 'Policies', 'and', 'Obligations', 'of', 'the', 'State']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(preprocessed))","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:43.847919Z","iopub.execute_input":"2024-09-10T07:56:43.848306Z","iopub.status.idle":"2024-09-10T07:56:43.862462Z","shell.execute_reply.started":"2024-09-10T07:56:43.848276Z","shell.execute_reply":"2024-09-10T07:56:43.860981Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"65101\n","output_type":"stream"}]},{"cell_type":"code","source":"#Unique tokens\nlen(set(preprocessed))","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:43.864032Z","iopub.execute_input":"2024-09-10T07:56:43.864421Z","iopub.status.idle":"2024-09-10T07:56:43.883258Z","shell.execute_reply.started":"2024-09-10T07:56:43.864392Z","shell.execute_reply":"2024-09-10T07:56:43.881954Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"4525"},"metadata":{}}]},{"cell_type":"markdown","source":"**Create a vocabulary**","metadata":{}},{"cell_type":"code","source":"all_words = sorted(set(preprocessed))\nvocab_size = len(all_words)\n\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:43.888008Z","iopub.execute_input":"2024-09-10T07:56:43.888372Z","iopub.status.idle":"2024-09-10T07:56:43.903558Z","shell.execute_reply.started":"2024-09-10T07:56:43.888345Z","shell.execute_reply":"2024-09-10T07:56:43.902267Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"4525\n","output_type":"stream"}]},{"cell_type":"code","source":"#Give indexes and put that as dictionary\nvocab = {token:integer for integer,token in enumerate(all_words)}","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:43.905563Z","iopub.execute_input":"2024-09-10T07:56:43.905961Z","iopub.status.idle":"2024-09-10T07:56:43.919417Z","shell.execute_reply.started":"2024-09-10T07:56:43.905929Z","shell.execute_reply":"2024-09-10T07:56:43.918253Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Simple Tokenization of text****","metadata":{}},{"cell_type":"code","source":"\"\"\"Putting all together\"\"\"\n\nclass SimpleTokenizerV1:\n    def __init__(self, vocab):\n        self.str_to_int = vocab\n        self.int_to_str = {i:s for s,i in vocab.items()}\n    \n    def encode(self, text):\n        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n                                \n        preprocessed = [\n            item.strip() for item in preprocessed if item.strip()\n        ]\n        ids = [self.str_to_int[s] for s in preprocessed]\n        return ids\n        \n    def decode(self, ids):\n        text = \" \".join([self.int_to_str[i] for i in ids])\n        # Replace spaces before the specified punctuations\n        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n        return text","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:43.921003Z","iopub.execute_input":"2024-09-10T07:56:43.921351Z","iopub.status.idle":"2024-09-10T07:56:43.934333Z","shell.execute_reply.started":"2024-09-10T07:56:43.921324Z","shell.execute_reply":"2024-09-10T07:56:43.933190Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tokenizer = SimpleTokenizerV1(vocab)\ntokenizer.encode(\"\"\" \"\"\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:43.936313Z","iopub.execute_input":"2024-09-10T07:56:43.936812Z","iopub.status.idle":"2024-09-10T07:56:43.959540Z","shell.execute_reply.started":"2024-09-10T07:56:43.936774Z","shell.execute_reply":"2024-09-10T07:56:43.958332Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Using Bytepair Encoding ","metadata":{}},{"cell_type":"code","source":"import importlib\nimport tiktoken\n\nprint(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:43.961155Z","iopub.execute_input":"2024-09-10T07:56:43.961573Z","iopub.status.idle":"2024-09-10T07:56:44.025738Z","shell.execute_reply.started":"2024-09-10T07:56:43.961544Z","shell.execute_reply":"2024-09-10T07:56:44.024502Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"tiktoken version: 0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = tiktoken.get_encoding(\"gpt2\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:44.027052Z","iopub.execute_input":"2024-09-10T07:56:44.027370Z","iopub.status.idle":"2024-09-10T07:56:47.676174Z","shell.execute_reply.started":"2024-09-10T07:56:44.027344Z","shell.execute_reply":"2024-09-10T07:56:47.674779Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"text = (\n    \"No law shall be made providing for the death penalty to any one<|endoftext|> Every citizen\"\n     \"of\"\n)\n\nintegers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n\nprint(integers)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:47.677547Z","iopub.execute_input":"2024-09-10T07:56:47.678610Z","iopub.status.idle":"2024-09-10T07:56:47.685956Z","shell.execute_reply.started":"2024-09-10T07:56:47.678574Z","shell.execute_reply":"2024-09-10T07:56:47.684552Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[2949, 1099, 2236, 307, 925, 4955, 329, 262, 1918, 7389, 284, 597, 530, 50256, 3887, 9511, 1659]\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.encode(\"fddfsdfsf\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:47.687254Z","iopub.execute_input":"2024-09-10T07:56:47.687577Z","iopub.status.idle":"2024-09-10T07:56:47.709411Z","shell.execute_reply.started":"2024-09-10T07:56:47.687551Z","shell.execute_reply":"2024-09-10T07:56:47.708167Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[69, 1860, 9501, 7568, 28202]"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode([1860])","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:47.710760Z","iopub.execute_input":"2024-09-10T07:56:47.711127Z","iopub.status.idle":"2024-09-10T07:56:47.728831Z","shell.execute_reply.started":"2024-09-10T07:56:47.711061Z","shell.execute_reply":"2024-09-10T07:56:47.727495Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'dd'"},"metadata":{}}]},{"cell_type":"markdown","source":"**Data Sampling with a sliding window**","metadata":{}},{"cell_type":"markdown","source":"**We train LLMs to generate one word at a time, so we want to prepare the training data accordingly where the next word in a sequence represents the target to predict**","metadata":{}},{"cell_type":"code","source":"import PyPDF2\n# Open the downloaded PDF file\nwith open(\"Constitution-of-Nepal_2072_Eng.pdf\", \"rb\") as file:\n    # Initialize a PDF reader object\n    pdf_reader = PyPDF2.PdfReader(file)\n    \n    # Extract text from each page of the PDF\n    raw_text = \"\"\n    for page_num in range(len(pdf_reader.pages)):\n        page = pdf_reader.pages[page_num]\n        raw_text += page.extract_text()\nenc_text = tokenizer.encode(raw_text)\nprint(len(enc_text))","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:47.730252Z","iopub.execute_input":"2024-09-10T07:56:47.730624Z","iopub.status.idle":"2024-09-10T07:56:57.084212Z","shell.execute_reply.started":"2024-09-10T07:56:47.730590Z","shell.execute_reply":"2024-09-10T07:56:57.082920Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"86531\n","output_type":"stream"}]},{"cell_type":"code","source":"\nvocab_size = len(set(enc_text))\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T08:00:28.280047Z","iopub.execute_input":"2024-09-10T08:00:28.280534Z","iopub.status.idle":"2024-09-10T08:00:28.290574Z","shell.execute_reply.started":"2024-09-10T08:00:28.280501Z","shell.execute_reply":"2024-09-10T08:00:28.289257Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"5305\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\n\nclass GPTDatasetV1(Dataset):\n    def __init__(self, txt, tokenizer, max_length, stride):\n        self.input_ids = []\n        self.target_ids = []\n\n        # Tokenize the entire text\n        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n\n        # Use a sliding window to chunk the book into overlapping sequences of max_length\n        for i in range(0, len(token_ids) - max_length, stride):\n            input_chunk = token_ids[i:i + max_length]\n            target_chunk = token_ids[i + 1: i + max_length + 1]\n            self.input_ids.append(torch.tensor(input_chunk))\n            self.target_ids.append(torch.tensor(target_chunk))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.target_ids[idx]","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:56:57.092559Z","iopub.execute_input":"2024-09-10T07:56:57.093016Z","iopub.status.idle":"2024-09-10T07:57:00.416980Z","shell.execute_reply.started":"2024-09-10T07:56:57.092975Z","shell.execute_reply":"2024-09-10T07:57:00.416030Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def create_dataloader_v1(txt, batch_size=4, max_length=256, \n                         stride=128, shuffle=True, drop_last=True,\n                         num_workers=0):\n\n    # Initialize the tokenizer\n    tokenizer = tiktoken.get_encoding(\"gpt2\")\n\n    # Create dataset\n    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n\n    # Create dataloader\n    dataloader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        drop_last=drop_last,\n        num_workers=num_workers\n    )\n\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:57:00.418593Z","iopub.execute_input":"2024-09-10T07:57:00.419143Z","iopub.status.idle":"2024-09-10T07:57:00.428056Z","shell.execute_reply.started":"2024-09-10T07:57:00.419111Z","shell.execute_reply":"2024-09-10T07:57:00.426771Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"**Test a dataloader with a batch size of 1 and context size of 4**","metadata":{}},{"cell_type":"code","source":"dataloader = create_dataloader_v1(\n    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n)\n\ndata_iter = iter(dataloader)\nfirst_batch = next(data_iter)\nprint(first_batch)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:57:00.429531Z","iopub.execute_input":"2024-09-10T07:57:00.429898Z","iopub.status.idle":"2024-09-10T07:57:02.311080Z","shell.execute_reply.started":"2024-09-10T07:57:00.429854Z","shell.execute_reply":"2024-09-10T07:57:02.309877Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"[tensor([[220, 198,  16, 220]]), tensor([[198,  16, 220, 198]])]\n","output_type":"stream"}]},{"cell_type":"code","source":"second_batch = next(data_iter)\nprint(second_batch)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:57:02.312478Z","iopub.execute_input":"2024-09-10T07:57:02.312822Z","iopub.status.idle":"2024-09-10T07:57:02.321394Z","shell.execute_reply.started":"2024-09-10T07:57:02.312793Z","shell.execute_reply":"2024-09-10T07:57:02.320225Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"[tensor([[198,  16, 220, 198]]), tensor([[ 16, 220, 198, 220]])]\n","output_type":"stream"}]},{"cell_type":"code","source":"dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n\ndata_iter = iter(dataloader)\ninputs, targets = next(data_iter)\nprint(\"Inputs:\\n\", inputs)\nprint(\"\\nTargets:\\n\", targets)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:57:02.323091Z","iopub.execute_input":"2024-09-10T07:57:02.323538Z","iopub.status.idle":"2024-09-10T07:57:03.189044Z","shell.execute_reply.started":"2024-09-10T07:57:02.323491Z","shell.execute_reply":"2024-09-10T07:57:03.187922Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Inputs:\n tensor([[  220,   198,    16,   220],\n        [  198,   220,   220,   198],\n        [  220,   198,   220,   198],\n        [  220,   198, 10970,  7102],\n        [ 2257,  2043, 35354,  3963],\n        [  399,  8905,  1847,   220],\n        [  220,   198,   220,   220],\n        [  220,   198,    17,   220]])\n\nTargets:\n tensor([[  198,    16,   220,   198],\n        [  220,   220,   198,   220],\n        [  198,   220,   198,   220],\n        [  198, 10970,  7102,  2257],\n        [ 2043, 35354,  3963,   399],\n        [ 8905,  1847,   220,   220],\n        [  198,   220,   220,   220],\n        [  198,    17,   220,   198]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Create token embeddings**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Coding an LLM Architecture","metadata":{}},{"cell_type":"code","source":"GPT_CONFIG_124M = {\n    \"vocab_size\": 5305,    # Vocabulary size from BPE\n    \"context_length\": 1024, # Context length\n    \"emb_dim\": 768,         # Embedding dimension\n    \"n_heads\": 12,          # Number of attention heads\n    \"n_layers\": 12,         # Number of layers\n    \"drop_rate\": 0.0,       # Dropout rate\n    \"qkv_bias\": True       # Query-Key-Value bias\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-10T07:57:03.190723Z","iopub.execute_input":"2024-09-10T07:57:03.191206Z","iopub.status.idle":"2024-09-10T07:57:03.197581Z","shell.execute_reply.started":"2024-09-10T07:57:03.191150Z","shell.execute_reply":"2024-09-10T07:57:03.196407Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"**Coding the GPT Model**","metadata":{}},{"cell_type":"code","source":"x_2 = inputs[1] # second input element\nd_in = inputs.shape[1] # the input embedding size, d=3\nd_out = 2 # the output embedding size, d=2","metadata":{"execution":{"iopub.status.busy":"2024-09-10T08:58:43.566940Z","iopub.execute_input":"2024-09-10T08:58:43.567454Z","iopub.status.idle":"2024-09-10T08:58:43.574608Z","shell.execute_reply.started":"2024-09-10T08:58:43.567411Z","shell.execute_reply":"2024-09-10T08:58:43.573271Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"print(inputs)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T08:59:11.320219Z","iopub.execute_input":"2024-09-10T08:59:11.320651Z","iopub.status.idle":"2024-09-10T08:59:11.328439Z","shell.execute_reply.started":"2024-09-10T08:59:11.320597Z","shell.execute_reply":"2024-09-10T08:59:11.327073Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"tensor([[  220,   198,    16,   220],\n        [  198,   220,   220,   198],\n        [  220,   198,   220,   198],\n        [  220,   198, 10970,  7102],\n        [ 2257,  2043, 35354,  3963],\n        [  399,  8905,  1847,   220],\n        [  220,   198,   220,   220],\n        [  220,   198,    17,   220]])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass SelfAttention_v1(nn.Module):\n\n    def __init__(self, d_in, d_out):\n        super().__init__()\n        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n\n    def forward(self, x):\n        # Ensure the input tensor is in float32 format\n        if x.dtype != torch.float32:\n            x = x.float()\n\n        keys = x @ self.W_key\n        queries = x @ self.W_query\n        values = x @ self.W_value\n        \n        attn_scores = queries @ keys.T # omega\n        attn_weights = torch.softmax(\n            attn_scores / keys.shape[-1]**0.5, dim=-1\n        )\n\n        context_vec = attn_weights @ values\n        return context_vec\ntorch.manual_seed(123)\n# Create the SelfAttention_v1 instance\nsa_v1 = SelfAttention_v1(d_in, d_out)\n# Forward pass\nprint(sa_v1(inputs))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T09:06:46.223627Z","iopub.execute_input":"2024-09-10T09:06:46.224062Z","iopub.status.idle":"2024-09-10T09:06:46.239820Z","shell.execute_reply.started":"2024-09-10T09:06:46.224027Z","shell.execute_reply":"2024-09-10T09:06:46.238704Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"tensor([[158.8819, 150.6755, 153.9783, 179.2892, 164.8145, 154.0112, 148.9656,\n         161.0673, 156.5470, 171.6551, 151.0642, 195.4609, 135.7174, 169.4190,\n         167.8739, 149.3526, 162.2017, 167.2431, 157.0390, 157.4042, 157.0929,\n         180.7577, 130.4422, 155.6458, 152.1001, 176.0182, 166.5292, 163.6009,\n         151.5780, 161.1508, 156.4633, 166.1018],\n        [158.8819, 150.6755, 153.9783, 179.2892, 164.8145, 154.0112, 148.9656,\n         161.0673, 156.5470, 171.6551, 151.0642, 195.4609, 135.7174, 169.4190,\n         167.8739, 149.3526, 162.2017, 167.2431, 157.0390, 157.4042, 157.0929,\n         180.7577, 130.4422, 155.6458, 152.1001, 176.0182, 166.5292, 163.6009,\n         151.5780, 161.1508, 156.4633, 166.1018],\n        [158.8819, 150.6755, 153.9783, 179.2892, 164.8145, 154.0112, 148.9656,\n         161.0673, 156.5470, 171.6551, 151.0642, 195.4609, 135.7174, 169.4190,\n         167.8739, 149.3526, 162.2017, 167.2431, 157.0390, 157.4042, 157.0929,\n         180.7577, 130.4422, 155.6458, 152.1001, 176.0182, 166.5292, 163.6009,\n         151.5780, 161.1508, 156.4633, 166.1018],\n        [158.8819, 150.6755, 153.9783, 179.2892, 164.8145, 154.0112, 148.9656,\n         161.0673, 156.5470, 171.6551, 151.0642, 195.4609, 135.7174, 169.4190,\n         167.8739, 149.3526, 162.2017, 167.2431, 157.0390, 157.4042, 157.0929,\n         180.7577, 130.4422, 155.6458, 152.1001, 176.0182, 166.5292, 163.6009,\n         151.5780, 161.1508, 156.4633, 166.1018],\n        [158.8819, 150.6755, 153.9783, 179.2892, 164.8145, 154.0112, 148.9656,\n         161.0673, 156.5470, 171.6551, 151.0642, 195.4609, 135.7174, 169.4190,\n         167.8739, 149.3526, 162.2017, 167.2431, 157.0390, 157.4042, 157.0929,\n         180.7577, 130.4422, 155.6458, 152.1001, 176.0182, 166.5292, 163.6009,\n         151.5780, 161.1508, 156.4633, 166.1018]], grad_fn=<MmBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"class SelfAttention_v2(nn.Module):\n\n    def __init__(self, d_in, d_out, qkv_bias=False):\n        super().__init__()\n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n\n    def forward(self, x):\n        if x.dtype != torch.float32:\n            x = x.float()\n\n        keys = self.W_key(x)\n        queries = self.W_query(x)\n        values = self.W_value(x)\n        \n        attn_scores = queries @ keys.T\n        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n\n        context_vec = attn_weights @ values\n        return context_vec\n\ntorch.manual_seed(789)\nsa_v2 = SelfAttention_v2(d_in, d_out)\nprint(sa_v2(inputs))","metadata":{"execution":{"iopub.status.busy":"2024-09-10T09:15:31.640282Z","iopub.execute_input":"2024-09-10T09:15:31.640705Z","iopub.status.idle":"2024-09-10T09:15:31.657888Z","shell.execute_reply.started":"2024-09-10T09:15:31.640673Z","shell.execute_reply":"2024-09-10T09:15:31.656445Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"tensor([[-3.2235, -3.7357,  3.6138, -6.4185, -0.0431, -0.1825, -2.7255,  3.2873,\n         -1.2094,  0.0430,  3.2942,  1.0218, -0.9350, -1.0848, -7.7038, -0.3324,\n          1.1618,  0.7010, -3.9985,  0.8794, -1.9087, -5.3913, -1.9001,  0.1609,\n          0.4097, -2.7980, -1.4895, -0.7474,  1.6869,  4.2371, -1.5783,  0.0826],\n        [-3.2234, -3.7357,  3.6137, -6.4184, -0.0430, -0.1826, -2.7255,  3.2872,\n         -1.2094,  0.0431,  3.2941,  1.0218, -0.9349, -1.0848, -7.7039, -0.3325,\n          1.1618,  0.7011, -3.9985,  0.8794, -1.9087, -5.3913, -1.9001,  0.1609,\n          0.4097, -2.7979, -1.4896, -0.7473,  1.6869,  4.2371, -1.5783,  0.0826],\n        [-3.2202, -3.7356,  3.6085, -6.4150, -0.0413, -0.1859, -2.7262,  3.2816,\n         -1.2054,  0.0490,  3.2879,  1.0218, -0.9315, -1.0841, -7.7069, -0.3341,\n          1.1612,  0.7050, -3.9960,  0.8781, -1.9092, -5.3891, -1.9025,  0.1632,\n          0.4129, -2.7931, -1.4912, -0.7430,  1.6863,  4.2395, -1.5787,  0.0827],\n        [-3.2223, -3.7353,  3.6116, -6.4169, -0.0432, -0.1828, -2.7259,  3.2851,\n         -1.2081,  0.0450,  3.2922,  1.0218, -0.9344, -1.0841, -7.7048, -0.3332,\n          1.1613,  0.7019, -3.9976,  0.8792, -1.9087, -5.3895, -1.9003,  0.1617,\n          0.4102, -2.7970, -1.4898, -0.7452,  1.6864,  4.2369, -1.5786,  0.0831],\n        [-3.2232, -3.7357,  3.6133, -6.4182, -0.0428, -0.1829, -2.7256,  3.2868,\n         -1.2090,  0.0436,  3.2936,  1.0218, -0.9346, -1.0848, -7.7041, -0.3326,\n          1.1617,  0.7014, -3.9983,  0.8792, -1.9088, -5.3912, -1.9003,  0.1611,\n          0.4100, -2.7975, -1.4897, -0.7470,  1.6869,  4.2374, -1.5784,  0.0825]],\n       grad_fn=<MmBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(type(sa_v2.W_query))","metadata":{"execution":{"iopub.status.busy":"2024-09-10T09:21:46.820072Z","iopub.execute_input":"2024-09-10T09:21:46.820522Z","iopub.status.idle":"2024-09-10T09:21:46.827801Z","shell.execute_reply.started":"2024-09-10T09:21:46.820489Z","shell.execute_reply":"2024-09-10T09:21:46.826307Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"<class 'torch.nn.modules.linear.Linear'>\n","output_type":"stream"}]},{"cell_type":"code","source":"# Reuse the query and key weight matrices\ninputs = inputs.float()\nqueries = sa_v2.W_query(inputs)\nkeys = sa_v2.W_key(inputs) \nattn_scores = queries @ keys.T\n\nattn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\nprint(attn_weights)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T09:34:17.391961Z","iopub.execute_input":"2024-09-10T09:34:17.392390Z","iopub.status.idle":"2024-09-10T09:34:17.404091Z","shell.execute_reply.started":"2024-09-10T09:34:17.392356Z","shell.execute_reply":"2024-09-10T09:34:17.402787Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"tensor([[6.2818e-12, 4.5580e-09, 7.2956e-06, 9.9999e-01, 6.9826e-10],\n        [2.6285e-08, 8.8171e-07, 3.4499e-05, 9.9996e-01, 5.2370e-07],\n        [1.2302e-08, 1.1123e-04, 1.3304e-03, 9.9856e-01, 1.6148e-06],\n        [7.6703e-08, 2.2564e-04, 2.9404e-04, 9.9945e-01, 2.7256e-05],\n        [3.8708e-07, 3.5687e-07, 1.4203e-04, 9.9986e-01, 1.0779e-07]],\n       grad_fn=<SoftmaxBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"context_length = attn_scores.shape[0]\nmask_simple = torch.tril(torch.ones(context_length, context_length))\nprint(mask_simple)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T09:34:56.011111Z","iopub.execute_input":"2024-09-10T09:34:56.012213Z","iopub.status.idle":"2024-09-10T09:34:56.021356Z","shell.execute_reply.started":"2024-09-10T09:34:56.012173Z","shell.execute_reply":"2024-09-10T09:34:56.019931Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"tensor([[1., 0., 0., 0., 0.],\n        [1., 1., 0., 0., 0.],\n        [1., 1., 1., 0., 0.],\n        [1., 1., 1., 1., 0.],\n        [1., 1., 1., 1., 1.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"print(attn_weights)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T09:35:58.112986Z","iopub.execute_input":"2024-09-10T09:35:58.113673Z","iopub.status.idle":"2024-09-10T09:35:58.122316Z","shell.execute_reply.started":"2024-09-10T09:35:58.113613Z","shell.execute_reply":"2024-09-10T09:35:58.120831Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"tensor([[6.2818e-12, 4.5580e-09, 7.2956e-06, 9.9999e-01, 6.9826e-10],\n        [2.6285e-08, 8.8171e-07, 3.4499e-05, 9.9996e-01, 5.2370e-07],\n        [1.2302e-08, 1.1123e-04, 1.3304e-03, 9.9856e-01, 1.6148e-06],\n        [7.6703e-08, 2.2564e-04, 2.9404e-04, 9.9945e-01, 2.7256e-05],\n        [3.8708e-07, 3.5687e-07, 1.4203e-04, 9.9986e-01, 1.0779e-07]],\n       grad_fn=<SoftmaxBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"masked_simple = attn_weights*mask_simple\nprint(masked_simple)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T09:35:31.597084Z","iopub.execute_input":"2024-09-10T09:35:31.597640Z","iopub.status.idle":"2024-09-10T09:35:31.605456Z","shell.execute_reply.started":"2024-09-10T09:35:31.597598Z","shell.execute_reply":"2024-09-10T09:35:31.604191Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"tensor([[6.2818e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [2.6285e-08, 8.8171e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [1.2302e-08, 1.1123e-04, 1.3304e-03, 0.0000e+00, 0.0000e+00],\n        [7.6703e-08, 2.2564e-04, 2.9404e-04, 9.9945e-01, 0.0000e+00],\n        [3.8708e-07, 3.5687e-07, 1.4203e-04, 9.9986e-01, 1.0779e-07]],\n       grad_fn=<MulBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"row_sums = masked_simple.sum(dim=-1, keepdim=True)\nmasked_simple_norm = masked_simple / row_sums\nprint(masked_simple_norm)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T09:37:02.301311Z","iopub.execute_input":"2024-09-10T09:37:02.301762Z","iopub.status.idle":"2024-09-10T09:37:02.310219Z","shell.execute_reply.started":"2024-09-10T09:37:02.301727Z","shell.execute_reply":"2024-09-10T09:37:02.308959Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [2.8948e-02, 9.7105e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [8.5336e-06, 7.7160e-02, 9.2283e-01, 0.0000e+00, 0.0000e+00],\n        [7.6705e-08, 2.2565e-04, 2.9404e-04, 9.9948e-01, 0.0000e+00],\n        [3.8708e-07, 3.5687e-07, 1.4203e-04, 9.9986e-01, 1.0779e-07]],\n       grad_fn=<DivBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}