{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Here I have made LLM model using GPT from scratch with constitution of Nepal.\nAll the works and references that I have done is taken from **Sebastian Raschka** book named  Build A Large Language Model (From Scratch).","metadata":{}},{"cell_type":"code","source":"!pip install tiktoken","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:51:33.012823Z","iopub.execute_input":"2024-09-16T08:51:33.013186Z","iopub.status.idle":"2024-09-16T08:51:46.694950Z","shell.execute_reply.started":"2024-09-16T08:51:33.013156Z","shell.execute_reply":"2024-09-16T08:51:46.693622Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting tiktoken\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\nDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tiktoken\nSuccessfully installed tiktoken-0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from importlib.metadata import version\n\nprint(\"torch version:\", version(\"torch\"))\nprint(\"tiktoken version:\", version(\"tiktoken\"))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:51:46.697056Z","iopub.execute_input":"2024-09-16T08:51:46.697361Z","iopub.status.idle":"2024-09-16T08:51:46.733250Z","shell.execute_reply.started":"2024-09-16T08:51:46.697331Z","shell.execute_reply":"2024-09-16T08:51:46.732402Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"torch version: 2.1.2\ntiktoken version: 0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import urllib\n\n# URL of the PDF file\nurl = \"https://ag.gov.np/files/Constitution-of-Nepal_2072_Eng_www.moljpa.gov_.npDate-72_11_16.pdf\"\n\n# Open the URL and download the PDF\nresponse = urllib.request.urlopen(url)\npdf_data = response.read()\n\n# Save the PDF to a local file\nwith open(\"Constitution-of-Nepal_2072_Eng.pdf\", \"wb\") as f:\n    f.write(pdf_data)\n\nprint(\"PDF downloaded and saved as 'Constitution-of-Nepal_2072_Eng.pdf'\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:51:46.734290Z","iopub.execute_input":"2024-09-16T08:51:46.734553Z","iopub.status.idle":"2024-09-16T08:51:49.304404Z","shell.execute_reply.started":"2024-09-16T08:51:46.734530Z","shell.execute_reply":"2024-09-16T08:51:49.303480Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"PDF downloaded and saved as 'Constitution-of-Nepal_2072_Eng.pdf'\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install PyPDF2","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:51:49.307280Z","iopub.execute_input":"2024-09-16T08:51:49.307994Z","iopub.status.idle":"2024-09-16T08:52:02.154462Z","shell.execute_reply.started":"2024-09-16T08:51:49.307954Z","shell.execute_reply":"2024-09-16T08:52:02.153540Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import PyPDF2\n\n# Open the downloaded PDF file\nwith open(\"Constitution-of-Nepal_2072_Eng.pdf\", \"rb\") as file:\n    # Initialize a PDF reader object\n    pdf_reader = PyPDF2.PdfReader(file)\n    \n    # Extract text from each page of the PDF\n    raw_text = \"\"\n    for page_num in range(len(pdf_reader.pages)):\n        page = pdf_reader.pages[page_num]\n        raw_text += page.extract_text()\n\n# Print the first 500 characters to preview the content\nprint(raw_text[:50])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:02.156028Z","iopub.execute_input":"2024-09-16T08:52:02.156424Z","iopub.status.idle":"2024-09-16T08:52:10.027826Z","shell.execute_reply.started":"2024-09-16T08:52:02.156381Z","shell.execute_reply":"2024-09-16T08:52:10.026948Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":" \n1 \n  \n \n \n \nTHE CONSTITUTION OF NEPAL  \n   \n2 \n \n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(raw_text))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:10.029158Z","iopub.execute_input":"2024-09-16T08:52:10.029483Z","iopub.status.idle":"2024-09-16T08:52:10.034067Z","shell.execute_reply.started":"2024-09-16T08:52:10.029457Z","shell.execute_reply":"2024-09-16T08:52:10.033152Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"344782\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Split text into tokens**","metadata":{}},{"cell_type":"code","source":"import re\npreprocessed = re.split(r'([,.:;?_!-\"()\\']|--|\\s|[@#%&])', raw_text)\n\npreprocessed = [item.strip() for item in preprocessed if item.strip()]\nprint(preprocessed[:30])","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:10.035186Z","iopub.execute_input":"2024-09-16T08:52:10.035445Z","iopub.status.idle":"2024-09-16T08:52:10.121290Z","shell.execute_reply.started":"2024-09-16T08:52:10.035422Z","shell.execute_reply":"2024-09-16T08:52:10.120444Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"['1', 'THE', 'CONSTITUTION', 'OF', 'NEPAL', '2', 'Table', 'of', 'Content', 's', 'Preamble', 'Part-1', 'Preliminary', 'Part-2', 'Citizenship', 'Part-3', 'Fundamental', 'Rights', 'and', 'Duties', 'Part-4', 'Directive', 'Principles', ',', 'Policies', 'and', 'Obligations', 'of', 'the', 'State']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(preprocessed))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:10.122354Z","iopub.execute_input":"2024-09-16T08:52:10.122632Z","iopub.status.idle":"2024-09-16T08:52:10.129786Z","shell.execute_reply.started":"2024-09-16T08:52:10.122608Z","shell.execute_reply":"2024-09-16T08:52:10.128961Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"65101\n","output_type":"stream"}]},{"cell_type":"code","source":"#Unique tokens\nlen(set(preprocessed))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:10.130876Z","iopub.execute_input":"2024-09-16T08:52:10.131299Z","iopub.status.idle":"2024-09-16T08:52:10.145182Z","shell.execute_reply.started":"2024-09-16T08:52:10.131268Z","shell.execute_reply":"2024-09-16T08:52:10.144311Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"4525"},"metadata":{}}]},{"cell_type":"markdown","source":"**Create a vocabulary**","metadata":{}},{"cell_type":"code","source":"all_words = sorted(set(preprocessed))\nvocab_size = len(all_words)\n\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:10.148983Z","iopub.execute_input":"2024-09-16T08:52:10.149692Z","iopub.status.idle":"2024-09-16T08:52:10.158881Z","shell.execute_reply.started":"2024-09-16T08:52:10.149666Z","shell.execute_reply":"2024-09-16T08:52:10.157970Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"4525\n","output_type":"stream"}]},{"cell_type":"code","source":"#Give indexes and put that as dictionary\nvocab = {token:integer for integer,token in enumerate(all_words)}","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:10.160028Z","iopub.execute_input":"2024-09-16T08:52:10.160304Z","iopub.status.idle":"2024-09-16T08:52:10.167277Z","shell.execute_reply.started":"2024-09-16T08:52:10.160282Z","shell.execute_reply":"2024-09-16T08:52:10.166485Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Simple Tokenization of text****","metadata":{}},{"cell_type":"code","source":"\"\"\"Putting all together\"\"\"\n\nclass SimpleTokenizerV1:\n    def __init__(self, vocab):\n        self.str_to_int = vocab\n        self.int_to_str = {i:s for s,i in vocab.items()}\n    \n    def encode(self, text):\n        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n                                \n        preprocessed = [\n            item.strip() for item in preprocessed if item.strip()\n        ]\n        ids = [self.str_to_int[s] for s in preprocessed]\n        return ids\n        \n    def decode(self, ids):\n        text = \" \".join([self.int_to_str[i] for i in ids])\n        # Replace spaces before the specified punctuations\n        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n        return text","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:10.168505Z","iopub.execute_input":"2024-09-16T08:52:10.168828Z","iopub.status.idle":"2024-09-16T08:52:10.179256Z","shell.execute_reply.started":"2024-09-16T08:52:10.168798Z","shell.execute_reply":"2024-09-16T08:52:10.178438Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tokenizer = SimpleTokenizerV1(vocab)\ntokenizer.encode(\"\"\" \"\"\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:10.180384Z","iopub.execute_input":"2024-09-16T08:52:10.180654Z","iopub.status.idle":"2024-09-16T08:52:10.190935Z","shell.execute_reply.started":"2024-09-16T08:52:10.180631Z","shell.execute_reply":"2024-09-16T08:52:10.190081Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Using Bytepair Encoding ","metadata":{}},{"cell_type":"code","source":"import importlib\nimport tiktoken\n\nprint(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:10.192063Z","iopub.execute_input":"2024-09-16T08:52:10.192313Z","iopub.status.idle":"2024-09-16T08:52:10.237989Z","shell.execute_reply.started":"2024-09-16T08:52:10.192292Z","shell.execute_reply":"2024-09-16T08:52:10.237143Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"tiktoken version: 0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = tiktoken.get_encoding(\"gpt2\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:10.239035Z","iopub.execute_input":"2024-09-16T08:52:10.239301Z","iopub.status.idle":"2024-09-16T08:52:12.002642Z","shell.execute_reply.started":"2024-09-16T08:52:10.239277Z","shell.execute_reply":"2024-09-16T08:52:12.001658Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"text = (\n    \"No law shall be made providing for the death penalty to any one<|endoftext|> Every citizen\"\n     \"of\"\n)\n\nintegers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n\nprint(integers)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:12.003749Z","iopub.execute_input":"2024-09-16T08:52:12.004057Z","iopub.status.idle":"2024-09-16T08:52:12.009643Z","shell.execute_reply.started":"2024-09-16T08:52:12.004032Z","shell.execute_reply":"2024-09-16T08:52:12.008715Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[2949, 1099, 2236, 307, 925, 4955, 329, 262, 1918, 7389, 284, 597, 530, 50256, 3887, 9511, 1659]\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.encode(\"fddfsdfsf\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:12.010672Z","iopub.execute_input":"2024-09-16T08:52:12.010973Z","iopub.status.idle":"2024-09-16T08:52:12.020220Z","shell.execute_reply.started":"2024-09-16T08:52:12.010941Z","shell.execute_reply":"2024-09-16T08:52:12.019395Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[69, 1860, 9501, 7568, 28202]"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode([1860])","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:12.021443Z","iopub.execute_input":"2024-09-16T08:52:12.021672Z","iopub.status.idle":"2024-09-16T08:52:12.029180Z","shell.execute_reply.started":"2024-09-16T08:52:12.021651Z","shell.execute_reply":"2024-09-16T08:52:12.028338Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'dd'"},"metadata":{}}]},{"cell_type":"markdown","source":"**Data Sampling with a sliding window**","metadata":{}},{"cell_type":"markdown","source":"**We train LLMs to generate one word at a time, so we want to prepare the training data accordingly where the next word in a sequence represents the target to predict**","metadata":{}},{"cell_type":"code","source":"import PyPDF2\n# Open the downloaded PDF file\nwith open(\"Constitution-of-Nepal_2072_Eng.pdf\", \"rb\") as file:\n    # Initialize a PDF reader object\n    pdf_reader = PyPDF2.PdfReader(file)\n    \n    # Extract text from each page of the PDF\n    raw_text = \"\"\n    for page_num in range(len(pdf_reader.pages)):\n        page = pdf_reader.pages[page_num]\n        raw_text += page.extract_text()\nenc_text = tokenizer.encode(raw_text)\nprint(len(enc_text))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:12.030391Z","iopub.execute_input":"2024-09-16T08:52:12.030998Z","iopub.status.idle":"2024-09-16T08:52:19.821164Z","shell.execute_reply.started":"2024-09-16T08:52:12.030966Z","shell.execute_reply":"2024-09-16T08:52:19.820255Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"86531\n","output_type":"stream"}]},{"cell_type":"code","source":"\nvocab_size = len(set(enc_text))\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:19.822365Z","iopub.execute_input":"2024-09-16T08:52:19.822667Z","iopub.status.idle":"2024-09-16T08:52:19.829922Z","shell.execute_reply.started":"2024-09-16T08:52:19.822643Z","shell.execute_reply":"2024-09-16T08:52:19.829064Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"5305\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\n\nclass GPTDatasetV1(Dataset):\n    def __init__(self, txt, tokenizer, max_length, stride):\n        self.input_ids = []\n        self.target_ids = []\n\n        # Tokenize the entire text\n        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n\n        # Use a sliding window to chunk the book into overlapping sequences of max_length\n        for i in range(0, len(token_ids) - max_length, stride):\n            input_chunk = token_ids[i:i + max_length]\n            target_chunk = token_ids[i + 1: i + max_length + 1]\n            self.input_ids.append(torch.tensor(input_chunk))\n            self.target_ids.append(torch.tensor(target_chunk))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.target_ids[idx]","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:19.830975Z","iopub.execute_input":"2024-09-16T08:52:19.831241Z","iopub.status.idle":"2024-09-16T08:52:23.259864Z","shell.execute_reply.started":"2024-09-16T08:52:19.831218Z","shell.execute_reply":"2024-09-16T08:52:23.258838Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def create_dataloader_v1(txt, batch_size=4, max_length=256, \n                         stride=128, shuffle=True, drop_last=True,\n                         num_workers=0):\n\n    # Initialize the tokenizer\n    tokenizer = tiktoken.get_encoding(\"gpt2\")\n\n    # Create dataset\n    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n\n    # Create dataloader\n    dataloader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        drop_last=drop_last,\n        num_workers=num_workers\n    )\n\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:23.261137Z","iopub.execute_input":"2024-09-16T08:52:23.261698Z","iopub.status.idle":"2024-09-16T08:52:23.267766Z","shell.execute_reply.started":"2024-09-16T08:52:23.261660Z","shell.execute_reply":"2024-09-16T08:52:23.266895Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"**Test a dataloader with a batch size of 1 and context size of 4**","metadata":{}},{"cell_type":"code","source":"dataloader = create_dataloader_v1(\n    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n)\n\ndata_iter = iter(dataloader)\nfirst_batch = next(data_iter)\nprint(first_batch)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:23.269041Z","iopub.execute_input":"2024-09-16T08:52:23.269365Z","iopub.status.idle":"2024-09-16T08:52:24.917677Z","shell.execute_reply.started":"2024-09-16T08:52:23.269340Z","shell.execute_reply":"2024-09-16T08:52:24.916752Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"[tensor([[220, 198,  16, 220]]), tensor([[198,  16, 220, 198]])]\n","output_type":"stream"}]},{"cell_type":"code","source":"second_batch = next(data_iter)\nprint(second_batch)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:24.919224Z","iopub.execute_input":"2024-09-16T08:52:24.919657Z","iopub.status.idle":"2024-09-16T08:52:24.926332Z","shell.execute_reply.started":"2024-09-16T08:52:24.919608Z","shell.execute_reply":"2024-09-16T08:52:24.925347Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"[tensor([[198,  16, 220, 198]]), tensor([[ 16, 220, 198, 220]])]\n","output_type":"stream"}]},{"cell_type":"code","source":"dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n\ndata_iter = iter(dataloader)\ninputs, targets = next(data_iter)\nprint(\"Inputs:\\n\", inputs)\nprint(\"\\nTargets:\\n\", targets)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:24.927810Z","iopub.execute_input":"2024-09-16T08:52:24.928197Z","iopub.status.idle":"2024-09-16T08:52:25.520713Z","shell.execute_reply.started":"2024-09-16T08:52:24.928164Z","shell.execute_reply":"2024-09-16T08:52:25.519753Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Inputs:\n tensor([[  220,   198,    16,   220],\n        [  198,   220,   220,   198],\n        [  220,   198,   220,   198],\n        [  220,   198, 10970,  7102],\n        [ 2257,  2043, 35354,  3963],\n        [  399,  8905,  1847,   220],\n        [  220,   198,   220,   220],\n        [  220,   198,    17,   220]])\n\nTargets:\n tensor([[  198,    16,   220,   198],\n        [  220,   220,   198,   220],\n        [  198,   220,   198,   220],\n        [  198, 10970,  7102,  2257],\n        [ 2043, 35354,  3963,   399],\n        [ 8905,  1847,   220,   220],\n        [  198,   220,   220,   220],\n        [  198,    17,   220,   198]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Create token embeddings**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Coding an LLM Architecture","metadata":{}},{"cell_type":"code","source":"GPT_CONFIG_124M = {\n    \"vocab_size\": 5305,    # Vocabulary size from BPE\n    \"context_length\": 1024, # Context length\n    \"emb_dim\": 768,         # Embedding dimension\n    \"n_heads\": 12,          # Number of attention heads\n    \"n_layers\": 12,         # Number of layers\n    \"drop_rate\": 0.0,       # Dropout rate\n    \"qkv_bias\": True       # Query-Key-Value bias\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.521854Z","iopub.execute_input":"2024-09-16T08:52:25.522170Z","iopub.status.idle":"2024-09-16T08:52:25.527146Z","shell.execute_reply.started":"2024-09-16T08:52:25.522142Z","shell.execute_reply":"2024-09-16T08:52:25.526127Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"**Coding the GPT Model**","metadata":{}},{"cell_type":"code","source":"x_2 = inputs[1] # second input element\nd_in = inputs.shape[1] # the input embedding size, d=3\nd_out = 2 # the output embedding size, d=2","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.528308Z","iopub.execute_input":"2024-09-16T08:52:25.528596Z","iopub.status.idle":"2024-09-16T08:52:25.540802Z","shell.execute_reply.started":"2024-09-16T08:52:25.528573Z","shell.execute_reply":"2024-09-16T08:52:25.539971Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"print(inputs)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.547963Z","iopub.execute_input":"2024-09-16T08:52:25.548265Z","iopub.status.idle":"2024-09-16T08:52:25.553529Z","shell.execute_reply.started":"2024-09-16T08:52:25.548242Z","shell.execute_reply":"2024-09-16T08:52:25.552705Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"tensor([[  220,   198,    16,   220],\n        [  198,   220,   220,   198],\n        [  220,   198,   220,   198],\n        [  220,   198, 10970,  7102],\n        [ 2257,  2043, 35354,  3963],\n        [  399,  8905,  1847,   220],\n        [  220,   198,   220,   220],\n        [  220,   198,    17,   220]])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass SelfAttention_v1(nn.Module):\n\n    def __init__(self, d_in, d_out):\n        super().__init__()\n        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n\n    def forward(self, x):\n        # Ensure the input tensor is in float32 format\n        if x.dtype != torch.float32:\n            x = x.float()\n\n        keys = x @ self.W_key\n        queries = x @ self.W_query\n        values = x @ self.W_value\n        \n        attn_scores = queries @ keys.T # omega\n        attn_weights = torch.softmax(\n            attn_scores / keys.shape[-1]**0.5, dim=-1\n        )\n\n        context_vec = attn_weights @ values\n        return context_vec\ntorch.manual_seed(123)\n# Create the SelfAttention_v1 instance\nsa_v1 = SelfAttention_v1(d_in, d_out)\n# Forward pass\nprint(sa_v1(inputs))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.554714Z","iopub.execute_input":"2024-09-16T08:52:25.554997Z","iopub.status.idle":"2024-09-16T08:52:25.660594Z","shell.execute_reply.started":"2024-09-16T08:52:25.554974Z","shell.execute_reply":"2024-09-16T08:52:25.659686Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"tensor([[33748.7266, 28081.3125],\n        [33748.7266, 28081.3125],\n        [33748.7266, 28081.3125],\n        [33748.7266, 28081.3125],\n        [33748.7266, 28081.3125],\n        [33748.7266, 28081.3125],\n        [33748.7266, 28081.3125],\n        [33748.7266, 28081.3125]], grad_fn=<MmBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"class SelfAttention_v2(nn.Module):\n\n    def __init__(self, d_in, d_out, qkv_bias=False):\n        super().__init__()\n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n\n    def forward(self, x):\n        if x.dtype != torch.float32:\n            x = x.float()\n\n        keys = self.W_key(x)\n        queries = self.W_query(x)\n        values = self.W_value(x)\n        \n        attn_scores = queries @ keys.T\n        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n\n        context_vec = attn_weights @ values\n        return context_vec\n\ntorch.manual_seed(789)\nsa_v2 = SelfAttention_v2(d_in, d_out)\nprint(sa_v2(inputs))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.661715Z","iopub.execute_input":"2024-09-16T08:52:25.662073Z","iopub.status.idle":"2024-09-16T08:52:25.677840Z","shell.execute_reply.started":"2024-09-16T08:52:25.662040Z","shell.execute_reply":"2024-09-16T08:52:25.676872Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"tensor([[-1047.0566, -1945.5106],\n        [-1047.0566, -1945.5106],\n        [-1047.0566, -1945.5106],\n        [-1047.0566, -1945.5106],\n        [-1047.0566, -1945.5106],\n        [-1047.0566, -1945.5106],\n        [-1047.0566, -1945.5106],\n        [-1047.0566, -1945.5106]], grad_fn=<MmBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(type(sa_v2.W_query))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.679184Z","iopub.execute_input":"2024-09-16T08:52:25.679898Z","iopub.status.idle":"2024-09-16T08:52:25.684745Z","shell.execute_reply.started":"2024-09-16T08:52:25.679863Z","shell.execute_reply":"2024-09-16T08:52:25.683754Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"<class 'torch.nn.modules.linear.Linear'>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Applying a causal attention mask**","metadata":{}},{"cell_type":"code","source":"# Reuse the query and key weight matrices of the\n# SelfAttention_v2 object from the previous section for convenience\ninputs = inputs.to(torch.float32)  # Ensure inputs are float32\n\nqueries = sa_v2.W_query(inputs)\nkeys = sa_v2.W_key(inputs) \nattn_scores = queries @ keys.T\n\nattn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\nprint(attn_weights)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.686080Z","iopub.execute_input":"2024-09-16T08:52:25.686435Z","iopub.status.idle":"2024-09-16T08:52:25.696044Z","shell.execute_reply.started":"2024-09-16T08:52:25.686403Z","shell.execute_reply":"2024-09-16T08:52:25.695068Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"tensor([[0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.]], grad_fn=<SoftmaxBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"context_length = attn_scores.shape[0]\nmask_simple = torch.tril(torch.ones(context_length, context_length))\nprint(mask_simple)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.697129Z","iopub.execute_input":"2024-09-16T08:52:25.697400Z","iopub.status.idle":"2024-09-16T08:52:25.708702Z","shell.execute_reply.started":"2024-09-16T08:52:25.697376Z","shell.execute_reply":"2024-09-16T08:52:25.707716Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 1., 0., 0., 0., 0., 0., 0.],\n        [1., 1., 1., 0., 0., 0., 0., 0.],\n        [1., 1., 1., 1., 0., 0., 0., 0.],\n        [1., 1., 1., 1., 1., 0., 0., 0.],\n        [1., 1., 1., 1., 1., 1., 0., 0.],\n        [1., 1., 1., 1., 1., 1., 1., 0.],\n        [1., 1., 1., 1., 1., 1., 1., 1.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"print(attn_weights)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.710010Z","iopub.execute_input":"2024-09-16T08:52:25.710786Z","iopub.status.idle":"2024-09-16T08:52:25.716372Z","shell.execute_reply.started":"2024-09-16T08:52:25.710748Z","shell.execute_reply":"2024-09-16T08:52:25.715391Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"tensor([[0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.]], grad_fn=<SoftmaxBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"masked_simple = attn_weights*mask_simple\nprint(masked_simple)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.717644Z","iopub.execute_input":"2024-09-16T08:52:25.717962Z","iopub.status.idle":"2024-09-16T08:52:25.725554Z","shell.execute_reply.started":"2024-09-16T08:52:25.717935Z","shell.execute_reply":"2024-09-16T08:52:25.724453Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.]], grad_fn=<MulBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"row_sums = masked_simple.sum(dim=-1, keepdim=True)\nmasked_simple_norm = masked_simple / row_sums\nprint(masked_simple_norm)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.726806Z","iopub.execute_input":"2024-09-16T08:52:25.727185Z","iopub.status.idle":"2024-09-16T08:52:25.734838Z","shell.execute_reply.started":"2024-09-16T08:52:25.727153Z","shell.execute_reply":"2024-09-16T08:52:25.733810Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"tensor([[nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.]], grad_fn=<DivBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\nmasked = attn_scores.masked_fill(mask.bool(), -torch.inf)\nprint(masked)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.736159Z","iopub.execute_input":"2024-09-16T08:52:25.736465Z","iopub.status.idle":"2024-09-16T08:52:25.749546Z","shell.execute_reply.started":"2024-09-16T08:52:25.736441Z","shell.execute_reply":"2024-09-16T08:52:25.748472Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"tensor([[-2.1879e+04,        -inf,        -inf,        -inf,        -inf,\n                -inf,        -inf,        -inf],\n        [-1.3480e+04, -1.7075e+04,        -inf,        -inf,        -inf,\n                -inf,        -inf,        -inf],\n        [-1.3992e+04, -1.7244e+04, -1.7778e+04,        -inf,        -inf,\n                -inf,        -inf,        -inf],\n        [ 2.9824e+04, -1.6149e+05, -1.5310e+05, -2.0735e+07,        -inf,\n                -inf,        -inf,        -inf],\n        [ 8.8224e+05, -2.4332e+05, -1.6096e+05, -7.7824e+07, -1.8636e+08,\n                -inf,        -inf,        -inf],\n        [-1.1653e+05, -2.6474e+05, -2.6475e+05, -2.4790e+07, -3.8156e+07,\n          5.6874e+06,        -inf,        -inf],\n        [-1.5006e+04, -1.7674e+04, -1.8277e+04, -1.2530e+06, -1.4423e+06,\n          3.6030e+05, -2.1175e+04,        -inf],\n        [-2.1845e+04, -1.7500e+04, -1.8679e+04, -8.5196e+05, -3.5977e+05,\n          3.3800e+05, -2.1408e+04, -2.1843e+04]],\n       grad_fn=<MaskedFillBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=-1)\nprint(attn_weights)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.750736Z","iopub.execute_input":"2024-09-16T08:52:25.751082Z","iopub.status.idle":"2024-09-16T08:52:25.758178Z","shell.execute_reply.started":"2024-09-16T08:52:25.751052Z","shell.execute_reply":"2024-09-16T08:52:25.757205Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.]], grad_fn=<SoftmaxBackward0>)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Masking additional attention weights with dropout**","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(123)\ndropout = torch.nn.Dropout(0.5) # dropout rate of 50%\nexample = torch.ones(6, 6) # create a matrix of ones\n\nprint(dropout(example))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.759509Z","iopub.execute_input":"2024-09-16T08:52:25.759787Z","iopub.status.idle":"2024-09-16T08:52:25.774588Z","shell.execute_reply.started":"2024-09-16T08:52:25.759765Z","shell.execute_reply":"2024-09-16T08:52:25.773730Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"tensor([[2., 2., 2., 2., 2., 2.],\n        [0., 2., 0., 0., 0., 0.],\n        [0., 0., 2., 0., 2., 0.],\n        [2., 2., 0., 0., 0., 2.],\n        [2., 0., 0., 0., 0., 2.],\n        [0., 2., 0., 0., 0., 0.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.manual_seed(123)\nprint(dropout(attn_weights))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.775583Z","iopub.execute_input":"2024-09-16T08:52:25.775883Z","iopub.status.idle":"2024-09-16T08:52:25.782034Z","shell.execute_reply.started":"2024-09-16T08:52:25.775860Z","shell.execute_reply":"2024-09-16T08:52:25.781145Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"tensor([[2., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [2., 0., 0., 0., 0., 0., 0., 0.],\n        [2., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 2., 0., 0.]], grad_fn=<MulBackward0>)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Now, we are ready to implement a working implementation of self-attention, including the causal and dropout masks**","metadata":{}},{"cell_type":"code","source":"batch = torch.stack((inputs, inputs), dim=0)\nprint(batch.shape) # 2 inputs with 8 tokens each, and each token has embedding dimension 4","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.783330Z","iopub.execute_input":"2024-09-16T08:52:25.783609Z","iopub.status.idle":"2024-09-16T08:52:25.790853Z","shell.execute_reply.started":"2024-09-16T08:52:25.783586Z","shell.execute_reply":"2024-09-16T08:52:25.789977Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"torch.Size([2, 8, 4])\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"Causal attention means that the model cannot look at the future,\nbut can take a look back\"\"\"\nclass CausalAttention(nn.Module):\n\n    def __init__(self, d_in, d_out, context_length,\n                 dropout, qkv_bias=False):\n        super().__init__()\n        self.d_out = d_out\n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.dropout = nn.Dropout(dropout) # New\n        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n\n    def forward(self, x):\n        b, num_tokens, d_in = x.shape # New batch dimension b\n        keys = self.W_key(x)\n        queries = self.W_query(x)\n        values = self.W_value(x)\n\n        attn_scores = queries @ keys.transpose(1, 2) # Changed transpose\n        attn_scores.masked_fill_(  # New, _ ops are in-place\n            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)  # `:num_tokens` to account for cases where the number of tokens in the batch is smaller than the supported context_size\n        attn_weights = torch.softmax(\n            attn_scores / keys.shape[-1]**0.5, dim=-1\n        )\n        attn_weights = self.dropout(attn_weights) # New\n\n        context_vec = attn_weights @ values\n        return context_vec\n\ntorch.manual_seed(123)\n\ncontext_length = batch.shape[1]\nca = CausalAttention(d_in, d_out, context_length, 0.0)\n\ncontext_vecs = ca(batch)\n\nprint(context_vecs)\nprint(\"context_vecs.shape:\", context_vecs.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.791829Z","iopub.execute_input":"2024-09-16T08:52:25.792127Z","iopub.status.idle":"2024-09-16T08:52:25.812170Z","shell.execute_reply.started":"2024-09-16T08:52:25.792090Z","shell.execute_reply":"2024-09-16T08:52:25.810943Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"tensor([[[ 1.4331e+01,  2.0460e+02],\n         [ 2.3399e+00,  2.1614e+02],\n         [-1.3254e+01,  2.2187e+02],\n         [-1.7280e+02,  5.0237e+03],\n         [-3.7248e+03,  7.7348e+03],\n         [ 1.4331e+01,  2.0460e+02],\n         [-3.7248e+03,  7.7348e+03],\n         [-3.7248e+03,  7.7348e+03]],\n\n        [[ 1.4331e+01,  2.0460e+02],\n         [ 2.3399e+00,  2.1614e+02],\n         [-1.3254e+01,  2.2187e+02],\n         [-1.7280e+02,  5.0237e+03],\n         [-3.7248e+03,  7.7348e+03],\n         [ 1.4331e+01,  2.0460e+02],\n         [-3.7248e+03,  7.7348e+03],\n         [-3.7248e+03,  7.7348e+03]]], grad_fn=<UnsafeViewBackward0>)\ncontext_vecs.shape: torch.Size([2, 8, 2])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Extending single-head attention to multi-head attention\n**Stacking multiple single-head attention layers**","metadata":{}},{"cell_type":"code","source":"class CausalAttention(nn.Module):\n    def __init__(self, d_in, d_out, dropout, qkv_bias=False):\n        super().__init__()\n        self.d_out = d_out\n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        b, num_tokens, d_in = x.shape  # New batch dimension b\n        keys = self.W_key(x)\n        queries = self.W_query(x)\n        values = self.W_value(x)\n        \n        # Example of attention mechanism (scaled dot-product attention)\n        attention_scores = torch.bmm(queries, keys.transpose(1, 2)) / (d_in ** 0.5)\n        attention_weights = torch.nn.functional.softmax(attention_scores, dim=-1)\n        attention_weights = self.dropout(attention_weights)\n        attended_values = torch.bmm(attention_weights, values)\n        \n        return attended_values  # Output dimension: (b, num_tokens, d_out)\n\nclass MultiHeadAttentionWrapper(nn.Module):\n    def __init__(self, d_in, d_out, dropout, num_heads, qkv_bias=False):\n        super().__init__()\n        self.heads = nn.ModuleList(\n            [CausalAttention(d_in, d_out, dropout, qkv_bias) for _ in range(num_heads)]\n        )\n    \n    def forward(self, x):\n        # Apply each attention head and concatenate the results\n        head_outputs = [head(x) for head in self.heads]\n        concat_output = torch.cat(head_outputs, dim=-1)  # Concatenate along the feature dimension\n        return concat_output\n\n# Example usage\ntorch.manual_seed(123)\n\nbatch = torch.randn(16, 10, 3)  # Example batch with shape (batch_size, context_length, d_in)\ncontext_length = batch.shape[1]\nd_in, d_out = 3, 2\nnum_heads = 2\n\nmha = MultiHeadAttentionWrapper(\n    d_in, d_out, dropout=0.0, num_heads=num_heads\n)\n\ncontext_vecs = mha(batch)\n\nprint(context_vecs)\nprint(\"context_vecs.shape:\", context_vecs.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.813849Z","iopub.execute_input":"2024-09-16T08:52:25.814375Z","iopub.status.idle":"2024-09-16T08:52:25.840771Z","shell.execute_reply.started":"2024-09-16T08:52:25.814350Z","shell.execute_reply":"2024-09-16T08:52:25.839992Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"tensor([[[ 3.4373e-02,  3.4932e-02, -1.8032e-02,  2.7194e-02],\n         [ 5.6516e-02,  1.2576e-02, -1.2246e-02, -2.2201e-03],\n         [ 4.3832e-02,  2.4913e-02, -8.2159e-03, -2.6836e-02],\n         [ 7.0120e-02,  3.9669e-02, -3.9439e-02,  1.1509e-01],\n         [ 5.6048e-02, -2.2458e-02, -2.1695e-02,  4.5938e-02],\n         [ 3.6287e-02,  4.3885e-02, -2.6986e-02,  6.6795e-02],\n         [ 5.5130e-02, -1.7051e-02, -7.5909e-03, -3.0422e-02],\n         [ 2.8773e-02, -1.8578e-03, -2.5042e-02,  6.0119e-02],\n         [ 2.1483e-02,  4.3345e-02, -3.3426e-03, -6.4934e-02],\n         [ 5.6056e-02,  5.0708e-02, -8.6930e-03, -2.4235e-02]],\n\n        [[-4.1947e-02,  9.0336e-02,  1.0794e-01, -1.5351e-01],\n         [-1.2100e-01, -3.1050e-04,  1.4609e-01, -2.9761e-01],\n         [-8.7553e-02,  6.6382e-03,  1.0577e-01, -1.3918e-01],\n         [-6.8727e-02, -7.0204e-02,  1.2272e-01, -2.1260e-01],\n         [-1.3041e-01, -3.2071e-02,  1.0984e-01, -1.5795e-01],\n         [-9.9118e-02, -2.5848e-02,  9.6548e-02, -8.3819e-02],\n         [-1.2179e-01, -4.6118e-02,  8.1016e-02,  4.7535e-02],\n         [-1.6143e-01, -3.1471e-02,  1.4267e-01, -2.8540e-01],\n         [-1.5254e-01, -6.5987e-02,  1.4700e-01, -2.9758e-01],\n         [-8.6071e-02, -3.2770e-02,  1.2007e-01, -2.0346e-01]],\n\n        [[-9.7510e-02,  2.9843e-02,  5.9200e-02, -4.3063e-02],\n         [-1.3190e-01, -2.8260e-02,  5.9088e-02, -4.7137e-02],\n         [-1.0451e-01,  3.7284e-02,  5.9026e-02, -4.1365e-02],\n         [-1.5678e-01,  3.1955e-02,  6.5130e-02, -1.0188e-01],\n         [-1.2579e-01,  3.1866e-03,  3.1417e-02,  7.8248e-02],\n         [-1.1364e-01,  1.0590e-02,  5.5248e-02, -2.3399e-02],\n         [-1.2328e-01,  3.5117e-02,  6.2639e-02, -6.4024e-02],\n         [-1.1327e-01, -2.8173e-02,  5.4844e-02, -2.3961e-02],\n         [-1.0528e-01,  4.4095e-03,  4.5886e-02,  1.9356e-02],\n         [-5.7157e-02,  7.2747e-02,  5.0482e-02,  2.8819e-03]],\n\n        [[-9.6168e-02,  1.3442e-02, -2.2610e-03,  4.6262e-02],\n         [-7.8097e-02, -1.7165e-02, -1.2515e-01,  3.7991e-01],\n         [-7.5603e-02,  1.0905e-01, -1.0293e-01,  3.1876e-01],\n         [-9.2609e-02, -2.4569e-02, -2.0928e-02,  9.5863e-02],\n         [-8.8278e-02, -1.0218e-01,  1.2838e-01, -2.8679e-01],\n         [-9.7940e-02, -1.0667e-02,  1.2895e-02,  6.3605e-03],\n         [-6.9872e-02,  5.3422e-03, -7.4611e-02,  2.4077e-01],\n         [-9.5563e-02,  2.0739e-02,  1.3791e-02,  3.9557e-03],\n         [-9.2867e-02, -4.5496e-02,  5.3579e-02, -9.9209e-02],\n         [-8.6697e-02,  1.2745e-03, -3.6187e-02,  1.3670e-01]],\n\n        [[-1.5232e-01,  6.5006e-02,  2.2938e-02,  2.5356e-02],\n         [-1.4101e-01, -2.8840e-02,  4.4505e-02, -4.9835e-02],\n         [-1.1209e-01,  1.5180e-01,  3.1300e-02, -1.0864e-03],\n         [-9.0656e-02,  1.1322e-01, -1.0472e-02,  1.4469e-01],\n         [-1.0215e-01,  7.4679e-02, -1.1943e-02,  1.4882e-01],\n         [-1.4340e-01,  1.1407e-01,  1.1383e-02,  6.6776e-02],\n         [-1.1001e-01, -2.6040e-02, -1.8887e-02,  1.7110e-01],\n         [-1.3364e-01,  6.3947e-02,  1.5565e-02,  5.0991e-02],\n         [-9.6096e-02,  2.6066e-02, -1.4253e-02,  1.5584e-01],\n         [-1.3494e-01,  2.6535e-02, -1.4101e-02,  1.5514e-01]],\n\n        [[ 6.3917e-02,  5.3121e-02, -9.9019e-02,  1.8194e-01],\n         [ 7.7839e-02,  1.2716e-01, -9.9818e-02,  1.8768e-01],\n         [ 6.3411e-02,  5.2023e-02, -9.3026e-02,  1.4254e-01],\n         [ 1.1655e-01, -3.5621e-02, -8.2368e-02,  7.3349e-02],\n         [ 1.0152e-01,  6.9429e-02, -1.1487e-01,  3.2169e-01],\n         [ 1.3036e-01,  2.3442e-02, -9.5445e-02,  1.5807e-01],\n         [ 7.4358e-02,  1.6751e-01, -8.4237e-02,  8.7460e-02],\n         [ 3.7175e-02,  8.1857e-02, -1.0487e-01,  2.2338e-01],\n         [ 9.1496e-02, -7.1089e-02, -1.0544e-01,  2.2713e-01],\n         [ 9.4935e-02,  3.4351e-02, -9.8224e-02,  1.7650e-01]],\n\n        [[-7.7532e-02, -2.0833e-01,  6.0579e-02, -1.2618e-01],\n         [-5.2588e-02, -6.2417e-02,  6.0419e-02, -1.1541e-01],\n         [-1.2741e-01,  9.5693e-02,  5.8489e-02, -8.2110e-02],\n         [-4.1889e-02, -6.5964e-02,  5.2832e-02, -4.8847e-02],\n         [-8.1910e-02,  1.3781e-01,  6.5169e-02, -1.3329e-01],\n         [-2.7717e-02, -4.1825e-02,  4.8512e-02, -5.1238e-04],\n         [-1.4855e-02,  4.5985e-02,  7.0473e-02, -1.8073e-01],\n         [-3.8620e-02, -8.8122e-03,  6.2669e-02, -1.2874e-01],\n         [-6.7145e-02, -1.6614e-02,  5.6114e-02, -7.3350e-02],\n         [-4.3532e-02, -1.3667e-02,  5.8317e-02, -9.3011e-02]],\n\n        [[ 3.9051e-02,  1.1978e-01, -1.0363e-01,  2.2909e-01],\n         [ 2.4146e-02,  1.2573e-01, -8.1671e-02,  1.9851e-01],\n         [ 4.4272e-02,  8.2349e-02, -7.3746e-02,  1.8903e-01],\n         [ 3.1177e-02,  8.2460e-02, -8.4559e-02,  2.0423e-01],\n         [ 4.2537e-02,  8.1325e-02, -9.3899e-02,  2.1741e-01],\n         [ 2.8814e-02,  1.2160e-01, -9.1301e-02,  2.1213e-01],\n         [ 3.4304e-02,  1.2259e-01, -1.0159e-01,  2.2617e-01],\n         [ 2.6479e-02,  8.2074e-02, -7.8124e-02,  1.9505e-01],\n         [ 3.6136e-02,  1.2853e-01, -6.9927e-02,  1.8159e-01],\n         [ 3.1992e-02,  1.2450e-01, -7.4518e-02,  1.8842e-01]],\n\n        [[-1.1385e-01,  9.6018e-02, -4.2744e-02,  1.6891e-01],\n         [-7.3978e-02, -1.0297e-02, -2.9244e-02,  9.1400e-02],\n         [-3.5980e-02,  1.4603e-01, -6.3750e-02,  2.7357e-01],\n         [-4.1244e-02,  9.7890e-02, -2.2620e-02,  5.8948e-02],\n         [-3.8404e-02,  6.4881e-02, -6.4267e-02,  2.7631e-01],\n         [-6.6044e-02,  9.3697e-02, -4.8984e-02,  2.0094e-01],\n         [-1.1213e-02,  1.7147e-01, -1.8134e-02,  3.9369e-02],\n         [-2.2765e-02,  1.1401e-01, -4.4300e-02,  1.7771e-01],\n         [ 1.1369e-02,  1.5610e-01, -9.2438e-02,  4.0512e-01],\n         [-1.0290e-01,  1.1837e-01, -4.2706e-02,  1.6943e-01]],\n\n        [[-2.1639e-01, -3.7982e-03,  1.0392e-01, -1.4224e-01],\n         [-2.2356e-01, -4.4817e-02,  1.2231e-01, -9.1746e-02],\n         [-1.7030e-01, -2.2158e-02,  1.2488e-01, -8.6634e-02],\n         [-1.9243e-01, -1.2409e-02,  1.1525e-01, -1.1193e-01],\n         [-1.9876e-01, -3.1244e-02,  1.1965e-01, -9.9340e-02],\n         [-1.8555e-01, -1.3743e-02,  1.1677e-01, -1.0796e-01],\n         [-1.9455e-01, -2.3029e-02,  1.0972e-01, -1.2432e-01],\n         [-1.7671e-01,  1.5992e-02,  1.1584e-01, -1.1340e-01],\n         [-2.2245e-01, -1.8793e-02,  1.1488e-01, -1.1275e-01],\n         [-1.8625e-01,  1.0369e-02,  1.1938e-01, -1.0426e-01]],\n\n        [[-9.6227e-03,  1.4852e-01, -7.0439e-02,  2.1788e-01],\n         [-2.0738e-02,  1.0285e-01, -6.0554e-02,  1.8394e-01],\n         [-1.0738e-02,  1.3498e-01, -7.0347e-02,  2.1736e-01],\n         [-4.9083e-03,  1.4639e-01, -7.7719e-02,  2.4435e-01],\n         [-4.3334e-02,  9.6553e-02, -6.0287e-02,  1.8316e-01],\n         [-4.0098e-02,  7.7093e-02, -6.2124e-02,  1.8878e-01],\n         [-1.6333e-02,  1.0442e-01, -7.4997e-02,  2.3357e-01],\n         [ 9.0646e-03,  1.6545e-01, -6.1662e-02,  1.8843e-01],\n         [ 2.6199e-03,  1.5066e-01, -8.2550e-02,  2.6409e-01],\n         [-1.5039e-03,  1.2942e-01, -7.5346e-02,  2.3513e-01]],\n\n        [[ 1.0141e-01, -8.6489e-02, -4.1942e-02, -3.2493e-02],\n         [ 1.0430e-01, -2.8643e-02, -3.4511e-02, -1.0388e-02],\n         [ 9.3669e-02, -2.3236e-03, -2.9731e-02,  3.9878e-03],\n         [ 8.5052e-02, -3.2383e-02, -2.3871e-02,  2.5407e-02],\n         [ 7.3696e-02, -2.2927e-02, -3.6849e-02, -2.2940e-02],\n         [ 1.2540e-01, -4.3128e-02, -8.4165e-03,  6.3756e-02],\n         [ 1.5785e-01,  5.3711e-02, -3.6970e-02, -3.3848e-02],\n         [ 6.6595e-02, -8.6153e-02, -3.2846e-02,  3.9109e-03],\n         [ 1.6567e-01,  7.1352e-02, -3.5490e-02, -2.8131e-02],\n         [ 1.4170e-02, -6.6271e-02, -4.1872e-02, -4.1057e-02]],\n\n        [[-4.7675e-02,  1.2454e-01, -1.4597e-01,  3.5089e-01],\n         [-6.0834e-02,  1.5073e-01, -1.5885e-01,  4.4160e-01],\n         [-5.6166e-02,  1.6745e-01, -1.6142e-01,  4.5475e-01],\n         [-4.1898e-02,  1.0094e-01, -1.6693e-01,  4.8320e-01],\n         [-6.1221e-02,  1.1709e-01, -1.5342e-01,  4.1024e-01],\n         [-5.7661e-02,  1.5064e-01, -1.5157e-01,  3.9642e-01],\n         [-7.9723e-02,  1.6182e-01, -1.6733e-01,  4.8365e-01],\n         [-4.3256e-02,  1.5248e-01, -1.5374e-01,  4.1100e-01],\n         [-8.5048e-02,  1.6947e-01, -1.4822e-01,  3.6980e-01],\n         [-5.4011e-02,  1.0227e-01, -1.5666e-01,  4.3054e-01]],\n\n        [[ 7.2949e-02, -1.5841e-01,  1.3868e-01, -4.1400e-01],\n         [ 7.3893e-02, -1.4669e-01,  1.6692e-01, -5.1486e-01],\n         [ 6.3354e-02, -1.3121e-01,  2.1127e-01, -6.8174e-01],\n         [ 1.0663e-01, -2.5356e-01,  1.0730e-01, -3.0682e-01],\n         [ 6.4506e-02, -9.7837e-02,  1.5540e-01, -4.7308e-01],\n         [ 1.1106e-01, -2.3214e-01,  1.0002e-01, -2.8266e-01],\n         [ 9.3221e-02, -1.2095e-01,  1.2898e-01, -3.8029e-01],\n         [ 1.3351e-01, -1.3744e-01,  6.5888e-02, -1.7270e-01],\n         [ 4.3460e-02, -2.0311e-01,  1.5162e-01, -4.5982e-01],\n         [ 7.3016e-02, -2.0550e-01,  1.9290e-01, -6.1178e-01]],\n\n        [[ 6.4976e-02,  7.8277e-02, -4.5628e-02,  9.9086e-02],\n         [ 6.1600e-02,  7.7655e-02, -4.8032e-02,  1.0411e-01],\n         [ 6.5277e-02,  9.2286e-02, -3.3532e-02,  7.2730e-02],\n         [ 6.5918e-02,  6.8079e-02, -7.9068e-02,  1.6860e-01],\n         [ 5.4721e-02,  5.0887e-02, -6.6256e-02,  1.4264e-01],\n         [ 5.0296e-02,  8.5925e-02, -3.6952e-02,  7.9905e-02],\n         [ 6.4070e-02,  1.1697e-01, -8.9554e-02,  1.8816e-01],\n         [ 6.0848e-02,  7.0070e-02, -6.5693e-02,  1.4115e-01],\n         [ 6.4504e-02,  1.2854e-01, -1.1210e-01,  2.3195e-01],\n         [ 5.5239e-02,  5.9495e-02, -3.6092e-02,  7.8802e-02]],\n\n        [[ 1.0938e-01, -1.8904e-01,  1.0466e-01, -4.2353e-01],\n         [ 1.0489e-01, -1.5534e-01,  1.0444e-01, -4.2491e-01],\n         [ 1.2645e-01, -1.6579e-01,  1.0491e-01, -4.2252e-01],\n         [ 1.5189e-01, -1.4650e-01,  1.0387e-01, -4.2788e-01],\n         [ 1.3558e-01, -1.8081e-01,  1.2870e-01, -3.8736e-01],\n         [ 7.7489e-02, -2.5336e-01,  1.0272e-01, -4.3801e-01],\n         [ 1.3564e-01, -1.6467e-01,  1.1391e-01, -4.0022e-01],\n         [ 1.1776e-01, -2.2489e-01,  1.2294e-01, -3.8880e-01],\n         [ 1.3119e-01, -1.7058e-01,  1.0942e-01, -4.0816e-01],\n         [ 9.9579e-02, -1.6876e-01,  1.1991e-01, -3.9375e-01]]],\n       grad_fn=<CatBackward0>)\ncontext_vecs.shape: torch.Size([16, 10, 4])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Implementing multi-head attention with weight splits","metadata":{}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n        super().__init__()\n        assert (d_out % num_heads == 0), \\\n            \"d_out must be divisible by num_heads\"\n\n        self.d_out = d_out\n        self.num_heads = num_heads\n        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n\n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer(\n            \"mask\",\n            torch.triu(torch.ones(context_length, context_length),\n                       diagonal=1)\n        )\n\n    def forward(self, x):\n        b, num_tokens, d_in = x.shape\n\n        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n        queries = self.W_query(x)\n        values = self.W_value(x)\n\n        # We implicitly split the matrix by adding a `num_heads` dimension\n        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n\n        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n        keys = keys.transpose(1, 2)\n        queries = queries.transpose(1, 2)\n        values = values.transpose(1, 2)\n\n        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n\n        # Original mask truncated to the number of tokens and converted to boolean\n        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n\n        # Use the mask to fill attention scores\n        attn_scores.masked_fill_(mask_bool, -torch.inf)\n        \n        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n        attn_weights = self.dropout(attn_weights)\n\n        # Shape: (b, num_tokens, num_heads, head_dim)\n        context_vec = (attn_weights @ values).transpose(1, 2) \n        \n        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n        context_vec = self.out_proj(context_vec) # optional projection\n\n        return context_vec\n\ntorch.manual_seed(123)\n\nbatch_size, context_length, d_in = batch.shape\nd_out = 2\nmha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n\ncontext_vecs = mha(batch)\n\nprint(context_vecs)\nprint(\"context_vecs.shape:\", context_vecs.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.842014Z","iopub.execute_input":"2024-09-16T08:52:25.842702Z","iopub.status.idle":"2024-09-16T08:52:25.868212Z","shell.execute_reply.started":"2024-09-16T08:52:25.842671Z","shell.execute_reply":"2024-09-16T08:52:25.867222Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"tensor([[[ 0.1829,  0.6533],\n         [ 0.2044,  0.6853],\n         [ 0.2343,  0.7194],\n         [ 0.0991,  0.7718],\n         [ 0.1481,  0.6130],\n         [ 0.1328,  0.6741],\n         [ 0.1988,  0.5684],\n         [ 0.1820,  0.5086],\n         [ 0.2775,  0.5498],\n         [ 0.2107,  0.6883]],\n\n        [[ 0.1155,  1.5834],\n         [ 0.3182,  1.2603],\n         [ 0.2205,  1.2699],\n         [ 0.2575,  1.0431],\n         [ 0.2662,  0.9379],\n         [ 0.1915,  0.9777],\n         [ 0.1005,  0.8624],\n         [ 0.3509,  0.7102],\n         [ 0.3911,  0.5504],\n         [ 0.2749,  0.7494]],\n\n        [[ 0.2119,  1.0297],\n         [ 0.2763,  0.6831],\n         [ 0.2420,  0.8347],\n         [ 0.4347,  0.7683],\n         [ 0.2326,  0.7210],\n         [ 0.2635,  0.7271],\n         [ 0.3182,  0.7598],\n         [ 0.2509,  0.7100],\n         [ 0.2235,  0.7215],\n         [ 0.1617,  0.9823]],\n\n        [[ 0.2018,  0.6495],\n         [ 0.0435,  0.7165],\n         [-0.1398,  1.4743],\n         [ 0.0688,  0.8622],\n         [ 0.2684,  0.5365],\n         [ 0.2063,  0.6413],\n         [-0.0230,  1.2061],\n         [ 0.1586,  0.7916],\n         [ 0.2191,  0.6432],\n         [ 0.1239,  0.8507]],\n\n        [[ 0.3127,  0.5516],\n         [ 0.3786,  0.3936],\n         [ 0.2153,  1.0278],\n         [ 0.1187,  1.3046],\n         [ 0.1309,  1.1819],\n         [ 0.2009,  0.9784],\n         [ 0.1689,  0.9345],\n         [ 0.2126,  0.8557],\n         [ 0.1348,  0.9996],\n         [ 0.1876,  0.8219]],\n\n        [[ 0.1808,  0.5003],\n         [ 0.1140,  0.8272],\n         [ 0.1779,  0.6876],\n         [ 0.2303,  0.6547],\n         [-0.0371,  0.6686],\n         [ 0.1043,  0.7255],\n         [ 0.1724,  0.8781],\n         [ 0.1361,  0.7592],\n         [ 0.1344,  0.5598],\n         [ 0.1295,  0.6781]],\n\n        [[ 0.3782,  0.1330],\n         [ 0.3474,  0.3002],\n         [ 0.3221,  0.3385],\n         [ 0.2758,  0.3864],\n         [ 0.2261,  0.7070],\n         [ 0.1743,  0.6729],\n         [ 0.2144,  0.7965],\n         [ 0.2522,  0.7074],\n         [ 0.2562,  0.6535],\n         [ 0.2405,  0.6947]],\n\n        [[ 0.3391,  1.0985],\n         [ 0.2525,  0.9132],\n         [ 0.1050,  0.7552],\n         [ 0.1724,  0.7118],\n         [ 0.1974,  0.7263],\n         [ 0.2238,  0.7592],\n         [ 0.2577,  0.8047],\n         [ 0.1934,  0.7331],\n         [ 0.1526,  0.7432],\n         [ 0.1575,  0.7382]],\n\n        [[ 0.2939,  0.3381],\n         [ 0.3440,  0.2050],\n         [ 0.1846,  0.6910],\n         [ 0.2737,  0.5913],\n         [ 0.1953,  0.6770],\n         [ 0.2237,  0.6207],\n         [ 0.2176,  0.8959],\n         [ 0.1856,  0.9099],\n         [ 0.0423,  1.1787],\n         [ 0.2280,  0.7569]],\n\n        [[ 0.4839,  1.0950],\n         [ 0.3305,  0.5995],\n         [ 0.1663,  0.7072],\n         [ 0.3105,  0.7794],\n         [ 0.2410,  0.7152],\n         [ 0.2611,  0.7739],\n         [ 0.3205,  0.7874],\n         [ 0.2917,  0.9013],\n         [ 0.3141,  0.8133],\n         [ 0.2675,  0.8989]],\n\n        [[ 0.1977,  0.8583],\n         [ 0.2472,  0.8418],\n         [ 0.2279,  0.8452],\n         [ 0.1884,  0.8366],\n         [ 0.2490,  0.7217],\n         [ 0.2609,  0.6734],\n         [ 0.2132,  0.7191],\n         [ 0.2360,  0.7962],\n         [ 0.1544,  0.8308],\n         [ 0.1602,  0.8255]],\n\n        [[ 0.2658,  0.4740],\n         [ 0.2177,  0.5589],\n         [ 0.1888,  0.5788],\n         [ 0.1585,  0.5298],\n         [ 0.1805,  0.5296],\n         [ 0.0210,  0.4566],\n         [ 0.1528,  0.6343],\n         [ 0.1166,  0.4941],\n         [ 0.1505,  0.6782],\n         [ 0.2441,  0.4361]],\n\n        [[ 0.2832,  1.0198],\n         [ 0.1491,  0.9843],\n         [ 0.0543,  1.1382],\n         [-0.0029,  0.9451],\n         [ 0.0851,  0.8296],\n         [ 0.0821,  0.9389],\n         [ 0.0341,  0.9265],\n         [ 0.0411,  1.0055],\n         [ 0.1166,  0.9632],\n         [ 0.0831,  0.8848]],\n\n        [[ 0.2574,  0.3990],\n         [ 0.2915,  0.5024],\n         [ 0.3935,  0.6200],\n         [ 0.3024,  0.3510],\n         [ 0.3331,  0.5190],\n         [ 0.2502,  0.3966],\n         [ 0.2455,  0.5510],\n         [ 0.1053,  0.7016],\n         [ 0.3746,  0.1576],\n         [ 0.3938,  0.1906]],\n\n        [[ 0.2509,  0.8881],\n         [ 0.2575,  0.8185],\n         [ 0.2784,  0.8928],\n         [ 0.1956,  0.8257],\n         [ 0.2245,  0.7212],\n         [ 0.2962,  0.6636],\n         [ 0.1898,  0.7152],\n         [ 0.2079,  0.6817],\n         [ 0.1215,  0.7088],\n         [ 0.2437,  0.6637]],\n\n        [[ 0.3485,  0.3623],\n         [ 0.3603,  0.4662],\n         [ 0.3431,  0.5156],\n         [ 0.3315,  0.6174],\n         [ 0.1734,  0.5099],\n         [ 0.3959,  0.1921],\n         [ 0.2769,  0.4321],\n         [ 0.1734,  0.3145],\n         [ 0.2732,  0.3631],\n         [ 0.2493,  0.3439]]], grad_fn=<ViewBackward0>)\ncontext_vecs.shape: torch.Size([16, 10, 2])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Pretraining LLMs","metadata":{}},{"cell_type":"code","source":"from importlib.metadata import version\n\npkgs = [\"matplotlib\", \n        \"numpy\", \n        \"tiktoken\", \n        \"torch\",\n        \"tensorflow\" # For OpenAI's pretrained weights\n       ]\nfor p in pkgs:\n    print(f\"{p} version: {version(p)}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.869477Z","iopub.execute_input":"2024-09-16T08:52:25.869759Z","iopub.status.idle":"2024-09-16T08:52:25.889600Z","shell.execute_reply.started":"2024-09-16T08:52:25.869735Z","shell.execute_reply":"2024-09-16T08:52:25.888692Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"matplotlib version: 3.7.5\nnumpy version: 1.26.4\ntiktoken version: 0.7.0\ntorch version: 2.1.2\ntensorflow version: 2.15.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# GPT Model","metadata":{}},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    def __init__(self, emb_dim):\n        super().__init__()\n        self.eps = 1e-5\n        self.scale = nn.Parameter(torch.ones(emb_dim))\n        self.shift = nn.Parameter(torch.zeros(emb_dim))\n\n    def forward(self, x):\n        mean = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n        return self.scale * norm_x + self.shift\nclass GELU(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(\n            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n            (x + 0.044715 * torch.pow(x, 3))\n        ))\n\nclass FeedForward(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n            GELU(),\n            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n        )\n\n    def forward(self, x):\n        return self.layers(x)\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.att = MultiHeadAttention(\n            d_in=cfg[\"emb_dim\"],\n            d_out=cfg[\"emb_dim\"],\n            context_length=cfg[\"context_length\"],\n            num_heads=cfg[\"n_heads\"],\n            dropout=cfg[\"drop_rate\"],\n            qkv_bias=cfg[\"qkv_bias\"])\n        self.ff = FeedForward(cfg)\n        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n\n    def forward(self, x):\n        # Shortcut connection for attention block\n        shortcut = x\n        x = self.norm1(x)\n        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n        x = self.drop_shortcut(x)\n        x = x + shortcut  # Add the original input back\n\n        # Shortcut connection for feed-forward block\n        shortcut = x\n        x = self.norm2(x)\n        x = self.ff(x)\n        x = self.drop_shortcut(x)\n        x = x + shortcut  # Add the original input back\n\n        return x\n\n\nclass GPTModel(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n\n        self.trf_blocks = nn.Sequential(\n            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n\n        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n\n    def forward(self, in_idx):\n        batch_size, seq_len = in_idx.shape\n        tok_embeds = self.tok_emb(in_idx)\n        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n        x = self.drop_emb(x)\n        x = self.trf_blocks(x)\n        x = self.final_norm(x)\n        logits = self.out_head(x)\n        return logits\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.890642Z","iopub.execute_input":"2024-09-16T08:52:25.890894Z","iopub.status.idle":"2024-09-16T08:52:25.909748Z","shell.execute_reply.started":"2024-09-16T08:52:25.890872Z","shell.execute_reply":"2024-09-16T08:52:25.908802Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"import torch\n\nGPT_CONFIG_124M = {\n    \"vocab_size\": 50257,   # Vocabulary size\n    \"context_length\": 256, # Shortened context length (orig: 1024)\n    \"emb_dim\": 768,        # Embedding dimension\n    \"n_heads\": 12,         # Number of attention heads\n    \"n_layers\": 12,        # Number of layers\n    \"drop_rate\": 0.1,      # Dropout rate\n    \"qkv_bias\": False      # Query-key-value bias\n}\n\ntorch.manual_seed(123)\nmodel = GPTModel(GPT_CONFIG_124M)\nmodel.eval();  # Disable dropout during inference","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:25.910782Z","iopub.execute_input":"2024-09-16T08:52:25.911045Z","iopub.status.idle":"2024-09-16T08:52:27.487396Z","shell.execute_reply.started":"2024-09-16T08:52:25.911022Z","shell.execute_reply":"2024-09-16T08:52:27.486379Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def generate_text_simple(model, idx, max_new_tokens, context_size):\n    # idx is (batch, n_tokens) array of indices in the current context\n    for _ in range(max_new_tokens):\n        \n        # Crop current context if it exceeds the supported context size\n        # E.g., if LLM supports only 5 tokens, and the context size is 10\n        # then only the last 5 tokens are used as context\n        idx_cond = idx[:, -context_size:]\n        \n        # Get the predictions\n        with torch.no_grad():\n            logits = model(idx_cond)\n        \n        # Focus only on the last time step\n        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n        logits = logits[:, -1, :]  \n\n        # Apply softmax to get probabilities\n        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n\n        # Get the idx of the vocab entry with the highest probability value\n        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n\n        # Append sampled index to the running sequence\n        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n\n    return idx","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:27.488509Z","iopub.execute_input":"2024-09-16T08:52:27.488849Z","iopub.status.idle":"2024-09-16T08:52:27.495963Z","shell.execute_reply.started":"2024-09-16T08:52:27.488822Z","shell.execute_reply":"2024-09-16T08:52:27.494956Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Using GPT to generate text","metadata":{}},{"cell_type":"code","source":"def text_to_token_ids(text, tokenizer):\n    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n    return encoded_tensor\n\ndef token_ids_to_text(token_ids, tokenizer):\n    flat = token_ids.squeeze(0) # remove batch dimension\n    return tokenizer.decode(flat.tolist())\n\nstart_context = \"Every effort moves you\"\ntokenizer = tiktoken.get_encoding(\"gpt2\")\n\ntoken_ids = generate_text_simple(\n    model=model,\n    idx=text_to_token_ids(start_context, tokenizer),\n    max_new_tokens=10,\n    context_size=GPT_CONFIG_124M[\"context_length\"]\n)\n\nprint(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:27.497167Z","iopub.execute_input":"2024-09-16T08:52:27.497449Z","iopub.status.idle":"2024-09-16T08:52:28.395428Z","shell.execute_reply.started":"2024-09-16T08:52:27.497417Z","shell.execute_reply":"2024-09-16T08:52:28.394351Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Output text:\n Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Calculating the text generation loss: cross-entropy and perplexity**","metadata":{}},{"cell_type":"code","source":"# First 100 characters\nprint(raw_text[:99])","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:28.396704Z","iopub.execute_input":"2024-09-16T08:52:28.397001Z","iopub.status.idle":"2024-09-16T08:52:28.401805Z","shell.execute_reply.started":"2024-09-16T08:52:28.396975Z","shell.execute_reply":"2024-09-16T08:52:28.400775Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":" \n1 \n  \n \n \n \nTHE CONSTITUTION OF NEPAL  \n   \n2 \n Table of Content s \n \nPreamble   \nPart-1  \nPrelim\n","output_type":"stream"}]},{"cell_type":"code","source":"total_characters = len(raw_text)\ntotal_tokens = len(tokenizer.encode(raw_text))\n\nprint(\"Characters:\", total_characters)\nprint(\"Tokens:\", total_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:28.403138Z","iopub.execute_input":"2024-09-16T08:52:28.403421Z","iopub.status.idle":"2024-09-16T08:52:28.484012Z","shell.execute_reply.started":"2024-09-16T08:52:28.403396Z","shell.execute_reply":"2024-09-16T08:52:28.483238Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Characters: 344782\nTokens: 86531\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Divide the dataset into a training and a validation set and use the data loaders to prepare the batches for LLM training**","metadata":{}},{"cell_type":"code","source":"def create_dataloader_v1(txt, batch_size=4, max_length=256,\n                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n    # Initialize the tokenizer\n    tokenizer = tiktoken.get_encoding(\"gpt2\")\n\n    # Create dataset\n    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n\n    # Create dataloader\n    dataloader = DataLoader(\n        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n\n    return dataloader\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:28.484959Z","iopub.execute_input":"2024-09-16T08:52:28.485231Z","iopub.status.idle":"2024-09-16T08:52:28.490873Z","shell.execute_reply.started":"2024-09-16T08:52:28.485208Z","shell.execute_reply":"2024-09-16T08:52:28.489882Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# Train/validation ratio\ntrain_ratio = 0.90\nsplit_idx = int(train_ratio * len(raw_text))\ntrain_data = raw_text[:split_idx]\nval_data = raw_text[split_idx:]\n\n\ntorch.manual_seed(123)\n\ntrain_loader = create_dataloader_v1(\n    train_data,\n    batch_size=2,\n    max_length=GPT_CONFIG_124M[\"context_length\"],\n    stride=GPT_CONFIG_124M[\"context_length\"],\n    drop_last=True,\n    shuffle=True,\n    num_workers=0\n)\n\nval_loader = create_dataloader_v1(\n    val_data,\n    batch_size=2,\n    max_length=GPT_CONFIG_124M[\"context_length\"],\n    stride=GPT_CONFIG_124M[\"context_length\"],\n    drop_last=False,\n    shuffle=False,\n    num_workers=0\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:28.491954Z","iopub.execute_input":"2024-09-16T08:52:28.492244Z","iopub.status.idle":"2024-09-16T08:52:28.642491Z","shell.execute_reply.started":"2024-09-16T08:52:28.492217Z","shell.execute_reply":"2024-09-16T08:52:28.641633Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# Sanity check\n\nif total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n    print(\"Not enough tokens for the training loader. \"\n          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n          \"increase the `training_ratio`\")\n\nif total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n    print(\"Not enough tokens for the validation loader. \"\n          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n          \"decrease the `training_ratio`\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:28.643682Z","iopub.execute_input":"2024-09-16T08:52:28.643977Z","iopub.status.idle":"2024-09-16T08:52:28.648905Z","shell.execute_reply.started":"2024-09-16T08:52:28.643947Z","shell.execute_reply":"2024-09-16T08:52:28.647989Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"print(\"Train loader:\")\nfor x, y in train_loader:\n    print(x.shape, y.shape)\n\nprint(\"\\nValidation loader:\")\nfor x, y in val_loader:\n    print(x.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:28.650205Z","iopub.execute_input":"2024-09-16T08:52:28.651024Z","iopub.status.idle":"2024-09-16T08:52:28.671077Z","shell.execute_reply.started":"2024-09-16T08:52:28.650950Z","shell.execute_reply":"2024-09-16T08:52:28.670255Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Train loader:\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\n\nValidation loader:\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\ntorch.Size([2, 256]) torch.Size([2, 256])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Another optional check that the token sizes are in the expected ballpark**\n","metadata":{}},{"cell_type":"code","source":"train_tokens = 0\nfor input_batch, target_batch in train_loader:\n    train_tokens += input_batch.numel()\n\nval_tokens = 0\nfor input_batch, target_batch in val_loader:\n    val_tokens += input_batch.numel()\n\nprint(\"Training tokens:\", train_tokens)\nprint(\"Validation tokens:\", val_tokens)\nprint(\"All tokens:\", train_tokens + val_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:28.672078Z","iopub.execute_input":"2024-09-16T08:52:28.672336Z","iopub.status.idle":"2024-09-16T08:52:28.687745Z","shell.execute_reply.started":"2024-09-16T08:52:28.672314Z","shell.execute_reply":"2024-09-16T08:52:28.686856Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Training tokens: 76800\nValidation tokens: 9216\nAll tokens: 86016\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**we implement a utility function to calculate the cross-entropy loss of a given batch\nIn addition, we implement a second utility function to compute the loss for a user-specified number of batches in a data loader**","metadata":{}},{"cell_type":"code","source":"def calc_loss_batch(input_batch, target_batch, model, device):\n    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n    logits = model(input_batch)\n    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n    return loss\n\n\ndef calc_loss_loader(data_loader, model, device, num_batches=None):\n    total_loss = 0.\n    if len(data_loader) == 0:\n        return float(\"nan\")\n    elif num_batches is None:\n        num_batches = len(data_loader)\n    else:\n        # Reduce the number of batches to match the total number of batches in the data loader\n        # if num_batches exceeds the number of batches in the data loader\n        num_batches = min(num_batches, len(data_loader))\n    for i, (input_batch, target_batch) in enumerate(data_loader):\n        if i < num_batches:\n            loss = calc_loss_batch(input_batch, target_batch, model, device)\n            total_loss += loss.item()\n        else:\n            break\n    return total_loss / num_batches","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:28.688877Z","iopub.execute_input":"2024-09-16T08:52:28.689183Z","iopub.status.idle":"2024-09-16T08:52:28.696755Z","shell.execute_reply.started":"2024-09-16T08:52:28.689160Z","shell.execute_reply":"2024-09-16T08:52:28.695929Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n\n\ntorch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n\nwith torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n    train_loss = calc_loss_loader(train_loader, model, device)\n    val_loss = calc_loss_loader(val_loader, model, device)\n\nprint(\"Training loss:\", train_loss)\nprint(\"Validation loss:\", val_loss)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:52:28.697848Z","iopub.execute_input":"2024-09-16T08:52:28.698196Z","iopub.status.idle":"2024-09-16T08:52:37.085313Z","shell.execute_reply.started":"2024-09-16T08:52:28.698166Z","shell.execute_reply":"2024-09-16T08:52:37.084358Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Training loss: 10.945489864349366\nValidation loss: 10.951971689860025\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training an LLM","metadata":{}},{"cell_type":"code","source":"def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n                       eval_freq, eval_iter, start_context, tokenizer):\n    # Initialize lists to track losses and tokens seen\n    train_losses, val_losses, track_tokens_seen = [], [], []\n    tokens_seen, global_step = 0, -1\n\n    # Main training loop\n    for epoch in range(num_epochs):\n        model.train()  # Set model to training mode\n        \n        for input_batch, target_batch in train_loader:\n            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n            loss = calc_loss_batch(input_batch, target_batch, model, device)\n            loss.backward() # Calculate loss gradients\n            optimizer.step() # Update model weights using loss gradients\n            tokens_seen += input_batch.numel()\n            global_step += 1\n\n            # Optional evaluation step\n            if global_step % eval_freq == 0:\n                train_loss, val_loss = evaluate_model(\n                    model, train_loader, val_loader, device, eval_iter)\n                train_losses.append(train_loss)\n                val_losses.append(val_loss)\n                track_tokens_seen.append(tokens_seen)\n                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n\n        # Print a sample text after each epoch\n        generate_and_print_sample(\n            model, tokenizer, device, start_context\n        )\n\n    return train_losses, val_losses, track_tokens_seen\n\n\ndef evaluate_model(model, train_loader, val_loader, device, eval_iter):\n    model.eval()\n    with torch.no_grad():\n        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n    model.train()\n    return train_loss, val_loss\n\n\ndef generate_and_print_sample(model, tokenizer, device, start_context):\n    model.eval()\n    context_size = model.pos_emb.weight.shape[0]\n    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n    with torch.no_grad():\n        token_ids = generate_text_simple(\n            model=model, idx=encoded,\n            max_new_tokens=50, context_size=context_size\n        )\n    decoded_text = token_ids_to_text(token_ids, tokenizer)\n    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n    model.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:53:48.437674Z","iopub.execute_input":"2024-09-16T08:53:48.438636Z","iopub.status.idle":"2024-09-16T08:53:48.455052Z","shell.execute_reply.started":"2024-09-16T08:53:48.438586Z","shell.execute_reply":"2024-09-16T08:53:48.453927Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"Now, let's train the LLM using the training function defined above:\n","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(123)\nmodel = GPTModel(GPT_CONFIG_124M)\nmodel.to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n\nnum_epochs = 10\ntrain_losses, val_losses, tokens_seen = train_model_simple(\n    model, train_loader, val_loader, optimizer, device,\n    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n    start_context=\"Sovereign People of Nepal\", tokenizer=tokenizer\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T08:55:25.725088Z","iopub.execute_input":"2024-09-16T08:55:25.725469Z","iopub.status.idle":"2024-09-16T09:03:16.287268Z","shell.execute_reply.started":"2024-09-16T08:55:25.725440Z","shell.execute_reply":"2024-09-16T09:03:16.286186Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Ep 1 (Step 000000): Train loss 8.985, Val loss 8.989\nEp 1 (Step 000005): Train loss 7.356, Val loss 7.408\nEp 1 (Step 000010): Train loss 6.463, Val loss 6.489\nEp 1 (Step 000015): Train loss 5.937, Val loss 5.992\nEp 1 (Step 000020): Train loss 5.660, Val loss 5.729\nEp 1 (Step 000025): Train loss 5.460, Val loss 5.630\nEp 1 (Step 000030): Train loss 5.629, Val loss 5.407\nEp 1 (Step 000035): Train loss 5.260, Val loss 5.303\nEp 1 (Step 000040): Train loss 5.359, Val loss 5.271\nEp 1 (Step 000045): Train loss 4.921, Val loss 5.005\nEp 1 (Step 000050): Train loss 5.293, Val loss 4.927\nEp 1 (Step 000055): Train loss 5.009, Val loss 4.907\nEp 1 (Step 000060): Train loss 4.865, Val loss 4.977\nEp 1 (Step 000065): Train loss 5.139, Val loss 4.817\nEp 1 (Step 000070): Train loss 4.916, Val loss 4.770\nEp 1 (Step 000075): Train loss 4.796, Val loss 4.725\nEp 1 (Step 000080): Train loss 4.290, Val loss 4.640\nEp 1 (Step 000085): Train loss 4.579, Val loss 4.568\nEp 1 (Step 000090): Train loss 4.273, Val loss 4.517\nEp 1 (Step 000095): Train loss 4.230, Val loss 4.523\nEp 1 (Step 000100): Train loss 4.495, Val loss 4.500\nEp 1 (Step 000105): Train loss 4.345, Val loss 4.468\nEp 1 (Step 000110): Train loss 4.511, Val loss 4.409\nEp 1 (Step 000115): Train loss 4.522, Val loss 4.363\nEp 1 (Step 000120): Train loss 4.351, Val loss 4.330\nEp 1 (Step 000125): Train loss 4.482, Val loss 4.299\nEp 1 (Step 000130): Train loss 4.304, Val loss 4.306\nEp 1 (Step 000135): Train loss 4.257, Val loss 4.284\nEp 1 (Step 000140): Train loss 3.952, Val loss 4.160\nEp 1 (Step 000145): Train loss 4.104, Val loss 4.151\nSovereign People of Nepal,  (2) The office of  (2) The President shall be as provided for the  (2) The President shall be as provided for the  (2) The President shall be as provided for the  \nEp 2 (Step 000150): Train loss 4.169, Val loss 4.146\nEp 2 (Step 000155): Train loss 3.944, Val loss 4.182\nEp 2 (Step 000160): Train loss 4.248, Val loss 4.194\nEp 2 (Step 000165): Train loss 3.830, Val loss 4.115\nEp 2 (Step 000170): Train loss 3.828, Val loss 4.091\nEp 2 (Step 000175): Train loss 3.850, Val loss 4.052\nEp 2 (Step 000180): Train loss 4.161, Val loss 4.017\nEp 2 (Step 000185): Train loss 4.114, Val loss 4.046\nEp 2 (Step 000190): Train loss 3.707, Val loss 4.058\nEp 2 (Step 000195): Train loss 3.400, Val loss 3.989\nEp 2 (Step 000200): Train loss 3.536, Val loss 4.039\nEp 2 (Step 000205): Train loss 3.941, Val loss 4.008\nEp 2 (Step 000210): Train loss 3.697, Val loss 4.037\nEp 2 (Step 000215): Train loss 3.609, Val loss 3.983\nEp 2 (Step 000220): Train loss 3.838, Val loss 3.944\nEp 2 (Step 000225): Train loss 4.217, Val loss 3.953\nEp 2 (Step 000230): Train loss 3.632, Val loss 3.881\nEp 2 (Step 000235): Train loss 3.274, Val loss 3.841\nEp 2 (Step 000240): Train loss 3.606, Val loss 3.866\nEp 2 (Step 000245): Train loss 3.576, Val loss 3.920\nEp 2 (Step 000250): Train loss 4.037, Val loss 3.884\nEp 2 (Step 000255): Train loss 3.334, Val loss 3.865\nEp 2 (Step 000260): Train loss 3.375, Val loss 3.797\nEp 2 (Step 000265): Train loss 3.372, Val loss 3.836\nEp 2 (Step 000270): Train loss 3.752, Val loss 3.791\nEp 2 (Step 000275): Train loss 3.663, Val loss 3.778\nEp 2 (Step 000280): Train loss 3.587, Val loss 3.830\nEp 2 (Step 000285): Train loss 3.281, Val loss 3.764\nEp 2 (Step 000290): Train loss 3.658, Val loss 3.806\nEp 2 (Step 000295): Train loss 3.245, Val loss 3.787\nSovereign People of Nepal,  (b) to the  (b) to the  (b) if he or she is declared because of the  (b) if he or she is removed from the  (a) if he or\nEp 3 (Step 000300): Train loss 3.378, Val loss 3.761\nEp 3 (Step 000305): Train loss 3.349, Val loss 3.729\nEp 3 (Step 000310): Train loss 3.618, Val loss 3.775\nEp 3 (Step 000315): Train loss 3.644, Val loss 3.762\nEp 3 (Step 000320): Train loss 2.980, Val loss 3.795\nEp 3 (Step 000325): Train loss 3.313, Val loss 3.707\nEp 3 (Step 000330): Train loss 3.335, Val loss 3.726\nEp 3 (Step 000335): Train loss 3.074, Val loss 3.742\nEp 3 (Step 000340): Train loss 3.227, Val loss 3.789\nEp 3 (Step 000345): Train loss 3.087, Val loss 3.792\nEp 3 (Step 000350): Train loss 3.243, Val loss 3.745\nEp 3 (Step 000355): Train loss 3.161, Val loss 3.765\nEp 3 (Step 000360): Train loss 3.179, Val loss 3.778\nEp 3 (Step 000365): Train loss 3.221, Val loss 3.752\nEp 3 (Step 000370): Train loss 3.344, Val loss 3.737\nEp 3 (Step 000375): Train loss 3.520, Val loss 3.799\nEp 3 (Step 000380): Train loss 2.791, Val loss 3.664\nEp 3 (Step 000385): Train loss 3.336, Val loss 3.627\nEp 3 (Step 000390): Train loss 3.246, Val loss 3.613\nEp 3 (Step 000395): Train loss 2.785, Val loss 3.671\nEp 3 (Step 000400): Train loss 2.933, Val loss 3.661\nEp 3 (Step 000405): Train loss 2.843, Val loss 3.632\nEp 3 (Step 000410): Train loss 2.819, Val loss 3.728\nEp 3 (Step 000415): Train loss 2.912, Val loss 3.732\nEp 3 (Step 000420): Train loss 3.141, Val loss 3.718\nEp 3 (Step 000425): Train loss 2.864, Val loss 3.658\nEp 3 (Step 000430): Train loss 3.191, Val loss 3.677\nEp 3 (Step 000435): Train loss 2.832, Val loss 3.628\nEp 3 (Step 000440): Train loss 3.056, Val loss 3.650\nEp 3 (Step 000445): Train loss 2.857, Val loss 3.659\nSovereign People of Nepal or  (e) to the  (e) to the  (e) to the  (e) to the  (e) to the  (e) to the  (e) to the\nEp 4 (Step 000450): Train loss 2.648, Val loss 3.609\nEp 4 (Step 000455): Train loss 2.904, Val loss 3.630\nEp 4 (Step 000460): Train loss 2.862, Val loss 3.609\nEp 4 (Step 000465): Train loss 2.673, Val loss 3.637\nEp 4 (Step 000470): Train loss 2.750, Val loss 3.611\nEp 4 (Step 000475): Train loss 2.876, Val loss 3.631\nEp 4 (Step 000480): Train loss 2.591, Val loss 3.584\nEp 4 (Step 000485): Train loss 2.675, Val loss 3.651\nEp 4 (Step 000490): Train loss 2.847, Val loss 3.605\nEp 4 (Step 000495): Train loss 2.491, Val loss 3.627\nEp 4 (Step 000500): Train loss 2.252, Val loss 3.621\nEp 4 (Step 000505): Train loss 2.727, Val loss 3.587\nEp 4 (Step 000510): Train loss 2.612, Val loss 3.601\nEp 4 (Step 000515): Train loss 2.594, Val loss 3.631\nEp 4 (Step 000520): Train loss 2.374, Val loss 3.638\nEp 4 (Step 000525): Train loss 2.642, Val loss 3.670\nEp 4 (Step 000530): Train loss 2.449, Val loss 3.659\nEp 4 (Step 000535): Train loss 2.330, Val loss 3.695\nEp 4 (Step 000540): Train loss 2.577, Val loss 3.732\nEp 4 (Step 000545): Train loss 2.374, Val loss 3.721\nEp 4 (Step 000550): Train loss 2.133, Val loss 3.655\nEp 4 (Step 000555): Train loss 2.401, Val loss 3.649\nEp 4 (Step 000560): Train loss 2.392, Val loss 3.659\nEp 4 (Step 000565): Train loss 2.097, Val loss 3.659\nEp 4 (Step 000570): Train loss 2.625, Val loss 3.639\nEp 4 (Step 000575): Train loss 2.422, Val loss 3.632\nEp 4 (Step 000580): Train loss 2.315, Val loss 3.627\nEp 4 (Step 000585): Train loss 2.477, Val loss 3.632\nEp 4 (Step 000590): Train loss 2.118, Val loss 3.640\nEp 4 (Step 000595): Train loss 2.367, Val loss 3.630\nSovereign People of Nepal.   (2) The term of the Chairperson and members of the Chairperson and members of the Chairperson  (3) The Chairperson  (3) The term of the Chairperson,  (a)\nEp 5 (Step 000600): Train loss 2.368, Val loss 3.606\nEp 5 (Step 000605): Train loss 1.815, Val loss 3.604\nEp 5 (Step 000610): Train loss 2.143, Val loss 3.640\nEp 5 (Step 000615): Train loss 2.000, Val loss 3.700\nEp 5 (Step 000620): Train loss 2.192, Val loss 3.745\nEp 5 (Step 000625): Train loss 2.263, Val loss 3.698\nEp 5 (Step 000630): Train loss 2.109, Val loss 3.680\nEp 5 (Step 000635): Train loss 2.250, Val loss 3.652\nEp 5 (Step 000640): Train loss 1.996, Val loss 3.648\nEp 5 (Step 000645): Train loss 1.997, Val loss 3.631\nEp 5 (Step 000650): Train loss 1.967, Val loss 3.678\nEp 5 (Step 000655): Train loss 1.812, Val loss 3.683\nEp 5 (Step 000660): Train loss 1.929, Val loss 3.680\nEp 5 (Step 000665): Train loss 2.108, Val loss 3.672\nEp 5 (Step 000670): Train loss 1.716, Val loss 3.703\nEp 5 (Step 000675): Train loss 2.168, Val loss 3.664\nEp 5 (Step 000680): Train loss 1.904, Val loss 3.705\nEp 5 (Step 000685): Train loss 2.050, Val loss 3.722\nEp 5 (Step 000690): Train loss 1.786, Val loss 3.719\nEp 5 (Step 000695): Train loss 1.805, Val loss 3.773\nEp 5 (Step 000700): Train loss 1.938, Val loss 3.753\nEp 5 (Step 000705): Train loss 1.967, Val loss 3.708\nEp 5 (Step 000710): Train loss 1.748, Val loss 3.765\nEp 5 (Step 000715): Train loss 1.764, Val loss 3.697\nEp 5 (Step 000720): Train loss 1.647, Val loss 3.715\nEp 5 (Step 000725): Train loss 1.777, Val loss 3.702\nEp 5 (Step 000730): Train loss 1.698, Val loss 3.681\nEp 5 (Step 000735): Train loss 1.700, Val loss 3.733\nEp 5 (Step 000740): Train loss 1.827, Val loss 3.687\nEp 5 (Step 000745): Train loss 1.693, Val loss 3.711\nSovereign People of Nepal,  (e) to make recommendations,  (d) to make planned and  (e) to make planned and    (7) to make special provisions for the  (8) to make recommendations to\nEp 6 (Step 000750): Train loss 1.728, Val loss 3.644\nEp 6 (Step 000755): Train loss 1.559, Val loss 3.645\nEp 6 (Step 000760): Train loss 1.632, Val loss 3.743\nEp 6 (Step 000765): Train loss 1.423, Val loss 3.718\nEp 6 (Step 000770): Train loss 1.517, Val loss 3.766\nEp 6 (Step 000775): Train loss 1.614, Val loss 3.739\nEp 6 (Step 000780): Train loss 1.573, Val loss 3.796\nEp 6 (Step 000785): Train loss 1.472, Val loss 3.803\nEp 6 (Step 000790): Train loss 1.538, Val loss 3.796\nEp 6 (Step 000795): Train loss 1.683, Val loss 3.765\nEp 6 (Step 000800): Train loss 1.410, Val loss 3.781\nEp 6 (Step 000805): Train loss 1.363, Val loss 3.815\nEp 6 (Step 000810): Train loss 1.236, Val loss 3.843\nEp 6 (Step 000815): Train loss 1.325, Val loss 3.825\nEp 6 (Step 000820): Train loss 1.453, Val loss 3.826\nEp 6 (Step 000825): Train loss 1.540, Val loss 3.846\nEp 6 (Step 000830): Train loss 1.262, Val loss 3.879\nEp 6 (Step 000835): Train loss 1.297, Val loss 3.876\nEp 6 (Step 000840): Train loss 1.274, Val loss 3.884\nEp 6 (Step 000845): Train loss 1.331, Val loss 3.883\nEp 6 (Step 000850): Train loss 1.227, Val loss 3.870\nEp 6 (Step 000855): Train loss 1.384, Val loss 3.851\nEp 6 (Step 000860): Train loss 1.150, Val loss 3.820\nEp 6 (Step 000865): Train loss 1.280, Val loss 3.852\nEp 6 (Step 000870): Train loss 1.269, Val loss 3.833\nEp 6 (Step 000875): Train loss 1.428, Val loss 3.776\nEp 6 (Step 000880): Train loss 1.128, Val loss 3.777\nEp 6 (Step 000885): Train loss 1.116, Val loss 3.841\nEp 6 (Step 000890): Train loss 1.111, Val loss 3.876\nEp 6 (Step 000895): Train loss 1.092, Val loss 3.878\nSovereign People of Nepal  the shares or the  Judicial Service  Explanation : For the purpos e of this Constitution and other fin ancial  who cannot be provided for in this Constitution and other judicial bodies.  shall be \nEp 7 (Step 000900): Train loss 1.188, Val loss 3.861\nEp 7 (Step 000905): Train loss 1.145, Val loss 3.926\nEp 7 (Step 000910): Train loss 0.977, Val loss 3.932\nEp 7 (Step 000915): Train loss 1.020, Val loss 3.928\nEp 7 (Step 000920): Train loss 1.205, Val loss 4.014\nEp 7 (Step 000925): Train loss 1.122, Val loss 4.083\nEp 7 (Step 000930): Train loss 0.916, Val loss 3.976\nEp 7 (Step 000935): Train loss 1.039, Val loss 3.910\nEp 7 (Step 000940): Train loss 0.957, Val loss 3.949\nEp 7 (Step 000945): Train loss 0.952, Val loss 4.030\nEp 7 (Step 000950): Train loss 0.829, Val loss 4.003\nEp 7 (Step 000955): Train loss 1.089, Val loss 3.981\nEp 7 (Step 000960): Train loss 0.930, Val loss 4.065\nEp 7 (Step 000965): Train loss 0.833, Val loss 4.077\nEp 7 (Step 000970): Train loss 0.871, Val loss 4.011\nEp 7 (Step 000975): Train loss 0.947, Val loss 4.029\nEp 7 (Step 000980): Train loss 0.856, Val loss 3.972\nEp 7 (Step 000985): Train loss 0.871, Val loss 4.007\nEp 7 (Step 000990): Train loss 0.698, Val loss 4.000\nEp 7 (Step 000995): Train loss 0.767, Val loss 4.018\nEp 7 (Step 001000): Train loss 0.843, Val loss 4.044\nEp 7 (Step 001005): Train loss 0.771, Val loss 4.005\nEp 7 (Step 001010): Train loss 0.854, Val loss 3.981\nEp 7 (Step 001015): Train loss 0.804, Val loss 4.016\nEp 7 (Step 001020): Train loss 0.692, Val loss 3.954\nEp 7 (Step 001025): Train loss 0.775, Val loss 3.952\nEp 7 (Step 001030): Train loss 1.006, Val loss 3.996\nEp 7 (Step 001035): Train loss 0.757, Val loss 4.023\nEp 7 (Step 001040): Train loss 0.608, Val loss 4.006\nEp 7 (Step 001045): Train loss 0.704, Val loss 4.031\nSovereign People of Nepal,  (e) to make   (b) to the basis of the basic needs,  in accordance with law in sub -based discrimination  national or  (c) to the Government of Nepal  d)\nEp 8 (Step 001050): Train loss 0.720, Val loss 4.074\nEp 8 (Step 001055): Train loss 0.668, Val loss 4.131\nEp 8 (Step 001060): Train loss 0.650, Val loss 4.172\nEp 8 (Step 001065): Train loss 0.777, Val loss 4.173\nEp 8 (Step 001070): Train loss 0.718, Val loss 4.130\nEp 8 (Step 001075): Train loss 0.690, Val loss 4.150\nEp 8 (Step 001080): Train loss 0.577, Val loss 4.229\nEp 8 (Step 001085): Train loss 0.665, Val loss 4.266\nEp 8 (Step 001090): Train loss 0.625, Val loss 4.246\nEp 8 (Step 001095): Train loss 0.580, Val loss 4.192\nEp 8 (Step 001100): Train loss 0.536, Val loss 4.218\nEp 8 (Step 001105): Train loss 0.658, Val loss 4.165\nEp 8 (Step 001110): Train loss 0.695, Val loss 4.192\nEp 8 (Step 001115): Train loss 0.671, Val loss 4.194\nEp 8 (Step 001120): Train loss 0.618, Val loss 4.217\nEp 8 (Step 001125): Train loss 0.545, Val loss 4.152\nEp 8 (Step 001130): Train loss 0.734, Val loss 4.180\nEp 8 (Step 001135): Train loss 0.718, Val loss 4.223\nEp 8 (Step 001140): Train loss 0.533, Val loss 4.252\nEp 8 (Step 001145): Train loss 0.511, Val loss 4.267\nEp 8 (Step 001150): Train loss 0.482, Val loss 4.217\nEp 8 (Step 001155): Train loss 0.510, Val loss 4.244\nEp 8 (Step 001160): Train loss 0.533, Val loss 4.258\nEp 8 (Step 001165): Train loss 0.636, Val loss 4.180\nEp 8 (Step 001170): Train loss 0.459, Val loss 4.224\nEp 8 (Step 001175): Train loss 0.565, Val loss 4.231\nEp 8 (Step 001180): Train loss 0.526, Val loss 4.233\nEp 8 (Step 001185): Train loss 0.586, Val loss 4.232\nEp 8 (Step 001190): Train loss 0.579, Val loss 4.249\nEp 8 (Step 001195): Train loss 0.480, Val loss 4.215\nSovereign People of Nepal or on any act assisting any act which or  clause or  to suc h pension as may be provided for in the Federal  law.  (2) Any conduct and act contrary to the Federal  Government of the Federal\nEp 9 (Step 001200): Train loss 0.434, Val loss 4.261\nEp 9 (Step 001205): Train loss 0.426, Val loss 4.219\nEp 9 (Step 001210): Train loss 0.525, Val loss 4.133\nEp 9 (Step 001215): Train loss 0.332, Val loss 4.276\nEp 9 (Step 001220): Train loss 0.517, Val loss 4.361\nEp 9 (Step 001225): Train loss 0.434, Val loss 4.316\nEp 9 (Step 001230): Train loss 0.373, Val loss 4.267\nEp 9 (Step 001235): Train loss 0.345, Val loss 4.258\nEp 9 (Step 001240): Train loss 0.363, Val loss 4.291\nEp 9 (Step 001245): Train loss 0.390, Val loss 4.333\nEp 9 (Step 001250): Train loss 0.387, Val loss 4.372\nEp 9 (Step 001255): Train loss 0.423, Val loss 4.323\nEp 9 (Step 001260): Train loss 0.343, Val loss 4.310\nEp 9 (Step 001265): Train loss 0.430, Val loss 4.339\nEp 9 (Step 001270): Train loss 0.343, Val loss 4.326\nEp 9 (Step 001275): Train loss 0.391, Val loss 4.315\nEp 9 (Step 001280): Train loss 0.487, Val loss 4.341\nEp 9 (Step 001285): Train loss 0.315, Val loss 4.325\nEp 9 (Step 001290): Train loss 0.331, Val loss 4.370\nEp 9 (Step 001295): Train loss 0.376, Val loss 4.368\nEp 9 (Step 001300): Train loss 0.388, Val loss 4.401\nEp 9 (Step 001305): Train loss 0.384, Val loss 4.360\nEp 9 (Step 001310): Train loss 0.397, Val loss 4.388\nEp 9 (Step 001315): Train loss 0.405, Val loss 4.362\nEp 9 (Step 001320): Train loss 0.398, Val loss 4.341\nEp 9 (Step 001325): Train loss 0.402, Val loss 4.449\nEp 9 (Step 001330): Train loss 0.333, Val loss 4.420\nEp 9 (Step 001335): Train loss 0.423, Val loss 4.397\nEp 9 (Step 001340): Train loss 0.331, Val loss 4.378\nEp 9 (Step 001345): Train loss 0.377, Val loss 4.402\nSovereign People of Nepal or of the  Nepal and on any Act, renewa l fee or for the imposition of fines or  penalty of imprisonment.  (3) if a High Court is required to be  Government of the Chief\nEp 10 (Step 001350): Train loss 0.370, Val loss 4.374\nEp 10 (Step 001355): Train loss 0.407, Val loss 4.389\nEp 10 (Step 001360): Train loss 0.331, Val loss 4.561\nEp 10 (Step 001365): Train loss 0.451, Val loss 4.665\nEp 10 (Step 001370): Train loss 0.319, Val loss 4.527\nEp 10 (Step 001375): Train loss 0.345, Val loss 4.468\nEp 10 (Step 001380): Train loss 0.371, Val loss 4.376\nEp 10 (Step 001385): Train loss 0.311, Val loss 4.471\nEp 10 (Step 001390): Train loss 0.354, Val loss 4.561\nEp 10 (Step 001395): Train loss 0.325, Val loss 4.541\nEp 10 (Step 001400): Train loss 0.381, Val loss 4.546\nEp 10 (Step 001405): Train loss 0.314, Val loss 4.580\nEp 10 (Step 001410): Train loss 0.265, Val loss 4.565\nEp 10 (Step 001415): Train loss 0.301, Val loss 4.547\nEp 10 (Step 001420): Train loss 0.399, Val loss 4.471\nEp 10 (Step 001425): Train loss 0.326, Val loss 4.465\nEp 10 (Step 001430): Train loss 0.381, Val loss 4.544\nEp 10 (Step 001435): Train loss 0.301, Val loss 4.612\nEp 10 (Step 001440): Train loss 0.270, Val loss 4.603\nEp 10 (Step 001445): Train loss 0.214, Val loss 4.565\nEp 10 (Step 001450): Train loss 0.283, Val loss 4.477\nEp 10 (Step 001455): Train loss 0.273, Val loss 4.484\nEp 10 (Step 001460): Train loss 0.304, Val loss 4.554\nEp 10 (Step 001465): Train loss 0.267, Val loss 4.496\nEp 10 (Step 001470): Train loss 0.286, Val loss 4.430\nEp 10 (Step 001475): Train loss 0.248, Val loss 4.565\nEp 10 (Step 001480): Train loss 0.263, Val loss 4.606\nEp 10 (Step 001485): Train loss 0.235, Val loss 4.591\nEp 10 (Step 001490): Train loss 0.289, Val loss 4.664\nEp 10 (Step 001495): Train loss 0.259, Val loss 4.561\nSovereign People of Nepal or a  147  authority, inhuman or degrading  (2) The committee under clause (3) shall  d)  of the course of the Supreme Court.   against himself or  (4\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\n\n\ndef plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n    fig, ax1 = plt.subplots(figsize=(5, 3))\n\n    # Plot training and validation loss against epochs\n    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n    ax1.set_xlabel(\"Epochs\")\n    ax1.set_ylabel(\"Loss\")\n    ax1.legend(loc=\"upper right\")\n    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n\n    # Create a second x-axis for tokens seen\n    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n    ax2.set_xlabel(\"Tokens seen\")\n\n    fig.tight_layout()  # Adjust layout to make room\n    plt.savefig(\"loss-plot.pdf\")\n    plt.show()\n\nepochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\nplot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:03:21.466406Z","iopub.execute_input":"2024-09-16T09:03:21.467318Z","iopub.status.idle":"2024-09-16T09:03:23.229183Z","shell.execute_reply.started":"2024-09-16T09:03:21.467285Z","shell.execute_reply":"2024-09-16T09:03:23.227882Z"},"trusted":true},"execution_count":62,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 500x300 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"model.to(\"cpu\")\nmodel.eval()\n\ntokenizer = tiktoken.get_encoding(\"gpt2\")\n\ntoken_ids = generate_text_simple(\n    model=model,\n    idx=text_to_token_ids(\"Sovereign People of Nepal\", tokenizer),\n    max_new_tokens=25,\n    context_size=GPT_CONFIG_124M[\"context_length\"]\n)\n\nprint(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:03:59.386572Z","iopub.execute_input":"2024-09-16T09:03:59.387408Z","iopub.status.idle":"2024-09-16T09:04:02.874003Z","shell.execute_reply.started":"2024-09-16T09:03:59.387373Z","shell.execute_reply":"2024-09-16T09:04:02.873079Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Output text:\n Sovereign People of Nepal or a \n147 \nauthority, inhuman or degrading \n(2) The committee under clause (3)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Modifying the text generation function**","metadata":{}},{"cell_type":"code","source":"def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n\n    # For-loop is the same as before: Get logits, and only focus on last time step\n    for _ in range(max_new_tokens):\n        idx_cond = idx[:, -context_size:]\n        with torch.no_grad():\n            logits = model(idx_cond)\n        logits = logits[:, -1, :]\n\n        # New: Filter logits with top_k sampling\n        if top_k is not None:\n            # Keep only top_k values\n            top_logits, _ = torch.topk(logits, top_k)\n            min_val = top_logits[:, -1]\n            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n\n        # New: Apply temperature scaling\n        if temperature > 0.0:\n            logits = logits / temperature\n\n            # Apply softmax to get probabilities\n            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n\n            # Sample from the distribution\n            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n\n        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n        else:\n            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n\n        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n            break\n\n        # Same as before: append sampled index to the running sequence\n        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n\n    return idx","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:12:17.588551Z","iopub.execute_input":"2024-09-16T09:12:17.588965Z","iopub.status.idle":"2024-09-16T09:12:17.598210Z","shell.execute_reply.started":"2024-09-16T09:12:17.588929Z","shell.execute_reply":"2024-09-16T09:12:17.597146Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(123)\n\ntoken_ids = generate(\n    model=model,\n    idx=text_to_token_ids(\"Sovereign People of Nepal\", tokenizer),\n    max_new_tokens=15,\n    context_size=GPT_CONFIG_124M[\"context_length\"],\n    top_k=25,\n    temperature=1.4\n)\n\nprint(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:12:58.071795Z","iopub.execute_input":"2024-09-16T09:12:58.072632Z","iopub.status.idle":"2024-09-16T09:12:59.592616Z","shell.execute_reply.started":"2024-09-16T09:12:58.072600Z","shell.execute_reply":"2024-09-16T09:12:59.591581Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Output text:\n Sovereign People of Nepal \nformed in the offices in the Federal  \nbetween the country\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#  Loading and saving model weights in PyTorch","metadata":{}},{"cell_type":"code","source":"#torch.save(model.state_dict(), \"model.pth\")\n","metadata":{},"execution_count":null,"outputs":[]}]}